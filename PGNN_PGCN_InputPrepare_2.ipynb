{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63cf08d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "from random import shuffle\n",
    "import math\n",
    "import torch\n",
    "import pdb\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, ConcatDataset\n",
    "import torch.optim as optim\n",
    "import scipy.interpolate as interp\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67a37366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "    # 查看文件中所有的数据集名称\n",
    "        dataset_names = list(f.keys())\n",
    "        print(\"Datasets in the file:\", dataset_names)\n",
    "        data_dict = {}\n",
    "        for name in dataset_names:\n",
    "            if f[name].shape == (): \n",
    "                data = f[name][()] \n",
    "            else:\n",
    "                data = f[name][:]\n",
    "        \n",
    "            data_dict[name] = data\n",
    "            \n",
    "        return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc665f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(data, file_path):\n",
    "    with open(file_path , 'wb') as f:\n",
    "        pickle.dump(data,f)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db0a8e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data_ash5(data, file_path):\n",
    "    with h5py.File(file_path, 'w') as f:\n",
    "        keys =list(data.keys())\n",
    "        for i in range(len(keys)):\n",
    "            f.create_dataset(keys[i], data=data[keys[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ae17eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_names = [\"Barcelona\",\"Antwerp\", \"Bangkok\"]\n",
    "root_path = \"D:/ThesisData/processed data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "feb66526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets in the file: ['city_node_num', 'max_vals', 'min_vals', 'period_template', 'target_template', 'trend_template']\n",
      "(71, 20, 21842, 5)\n"
     ]
    }
   ],
   "source": [
    "city_name = city_names[2]\n",
    "city_dict = read_data(root_path + city_name + \"/input_target/input_target.h5\")\n",
    "print(city_dict['period_template'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa480f35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e58fa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_divide(city_name, city_dict, indices, root_path, train_ratio, val_ratio, purpose):\n",
    "    ratio_dict = dict()\n",
    "    \n",
    "    keys = list(city_dict.keys())\n",
    "    train_size = int(train_ratio * city_dict['period_template'].shape[0])\n",
    "    val_size = int(val_ratio * city_dict['period_template'].shape[0])\n",
    "    test_size = city_dict['period_template'].shape[0] - train_size - val_size\n",
    "    city_node_num = city_dict['city_node_num']\n",
    "    three_element_list = ['period_template', 'target_template', 'trend_template']\n",
    "    \n",
    "    for key in keys:\n",
    "        if key in three_element_list:\n",
    "            if purpose == \"train\":\n",
    "                ratio_dict[key] = city_dict[key][indices][:train_size, :, :city_node_num, :].astype(np.float32)\n",
    "            elif purpose == \"vali\":\n",
    "                ratio_dict[key] = city_dict[key][indices][train_size:train_size+val_size, :, :city_node_num, :].astype(np.float32)\n",
    "            elif purpose == \"test\":\n",
    "                ratio_dict[key] = city_dict[key][indices][train_size+val_size: , :, :city_node_num, :].astype(np.float32)\n",
    "        elif key == \"city_node_num\":\n",
    "            ratio_dict[key] = city_node_num\n",
    "        else:\n",
    "            ratio_dict[key] = city_dict[key]\n",
    "            \n",
    "    save_data_ash5(ratio_dict, root_path + city_name + f\"/input_target/{purpose}.h5\")\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ef69df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "train_ratio, val_ratio = 0.6, 0.2\n",
    "purposes = ['train','test','vali']\n",
    "#Shuffled indicies\n",
    "indices = np.random.permutation(city_dict['period_template'].shape[0])\n",
    "for purpose in purposes:\n",
    "    percent_divide(city_name, city_dict, indices, root_path, train_ratio, val_ratio, purpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d26b02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
