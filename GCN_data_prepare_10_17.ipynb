{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "377931ad-09e0-40ab-a4d9-a967a5ad66bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\Cuda_env\\lib\\site-packages\\networkx\\utils\\backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback\n",
      "  backends.update(_get_backends(\"networkx.backends\"))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.data import Data, Dataset\n",
    "import networkx as nx\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b57d2757-eb2b-422d-b9db-d395eb82d341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_data(file_path):\n",
    "    file = open(file_path,\"rb\")\n",
    "    raw_data = pickle.load(file)  \n",
    "    return raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f5bdb61-8742-4928-be12-15d699479b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomGraphData(Data):\n",
    "    def __init__(self, x=None, edge_index=None, edge_attr=None, y=None, class_label=None, min_vals=None, max_vals=None):\n",
    "        # 正确调用父类的构造函数\n",
    "        super(CustomGraphData, self).__init__(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
    "        \n",
    "        # 添加自定义属性\n",
    "        self.class_label = class_label\n",
    "        self.min_vals = min_vals\n",
    "        self.max_vals = max_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a9eea89-714b-40fb-9904-9ebce6a15dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomGraphDataset(Dataset):\n",
    "    def __init__(self, data_list):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_list (list): 包含多个 CustomGraphData 对象的列表\n",
    "        \"\"\"\n",
    "        super(CustomGraphDataset, self).__init__()\n",
    "        self.data_list = data_list\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def get(self, idx):\n",
    "        return self.data_list[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0e197ab-75e2-4ff7-b1f2-616ec15247e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_graph_data(city_names, total_ratio = 0.8 ,train_ratio = 0.6):\n",
    "    graphs_list = list()\n",
    "    for i in range(len(city_names)):\n",
    "        city_dictionary = open_data(f\"D:/ThesisData/processed data/{city_names[i]}/NEW/{city_names[i]}_data_14days.h5\")\n",
    "        #-----------------------------------------------------------------------------\n",
    "        subgraph = city_dictionary[\"biggest_subgraph\"]\n",
    "        sorted_nodes = sorted(subgraph.nodes())\n",
    "        #-----------------------------------------------------------------------------\n",
    "        mapping = {old_label: new_label for new_label, old_label in enumerate(sorted_nodes, start=0)}\n",
    "        subgraph = nx.relabel_nodes(subgraph, mapping)    \n",
    "        #-----------------------------------------------------------------------------\n",
    "\n",
    "        \n",
    "        #-----------------------------------------------------------------------------\n",
    "        edge_pairs = []\n",
    "        edge_weights = []\n",
    "        for u, v, data in subgraph.edges(data=True):\n",
    "            edge_pairs.append([u, v])\n",
    "            edge_weights.append(data['weight'])\n",
    "        edge_pairs, edge_weights = np.transpose(np.array(edge_pairs)), np.array(edge_weights)        \n",
    "\n",
    "        #-----------------------------------------------------------------------------\n",
    "        total_scale, train_scale, vali_scale = 0, 0, 0\n",
    "        if city_names[i] == \"Antwerp\" or city_names[i] == \"Bangkok\" :\n",
    "            total_scale = int(total_ratio * city_dictionary[\"input_result\"].shape[0])\n",
    "        else:    \n",
    "            total_scale = int(total_ratio * city_dictionary[\"input_result\"].shape[0] * 0.5)\n",
    "\n",
    "        \n",
    "        train_scale = int(train_ratio * total_scale)\n",
    "\n",
    "        \n",
    "        input_ = city_dictionary[\"input_result\"][:train_scale]\n",
    "        target_ = city_dictionary[\"target_result\"][:train_scale]\n",
    "        print(f\"train length: {train_scale}\")\n",
    "                \n",
    "\n",
    "        \n",
    "        for j in range(input_.shape[0]):\n",
    "            # x  SHAPE: 28, Node_num, 1\n",
    "            #-----------------------------------------------------------\n",
    "            #first_feature = input_[..., 0]\n",
    "            #is_sorted = np.all(np.diff(first_feature, axis=-1) >= 0)\n",
    "            #print(\"Is sorted in ascending order?\", is_sorted)\n",
    "            #-----------------------------------------------------------\n",
    "            x = torch.tensor(input_[j], dtype= torch.float)[:,:,1:]\n",
    "            # x  SHAPE: Node_num, 28\n",
    "            x = x.permute(1, 0, 2).squeeze(-1)\n",
    "            if j == 1:\n",
    "                print(f\"City {city_names[i]} train input Shape: {x.shape}\")\n",
    "            #---------------------------------\n",
    "            # y SHAPE: 14, Node_num, 1\n",
    "            y = torch.tensor(target_[j], dtype= torch.float)[:,:,1:]\n",
    "            y = y.permute(1, 0, 2).squeeze(-1)\n",
    "            #--------------------------------\n",
    "            if j == 1:\n",
    "                print(f\"City {city_names[i]} train target Shape: {y.shape}\")\n",
    "            #city_dictionary[\"min_vals\"] SHAPE:\n",
    "            min_vals = torch.tensor(city_dictionary[\"min_vals\"], dtype=torch.float).unsqueeze(-1).unsqueeze(-1)\n",
    "            max_vals = torch.tensor(city_dictionary[\"max_vals\"], dtype=torch.float).unsqueeze(-1).unsqueeze(-1)\n",
    "            #_--------------------------------\n",
    "            \n",
    "            # EDGE INDEX SHAPE: 2, PAIR_NUM\n",
    "            edge_index = torch.tensor(edge_pairs, dtype= torch.long)\n",
    "            #  SHAPE: PAIR_NUM, \n",
    "            edge_attr = torch.tensor(edge_weights, dtype=torch.float)\n",
    "            #-----------------------------------\n",
    "            \n",
    "            if city_names[i]==\"Antwerp\" or city_names[i]==\"Bangkok\":\n",
    "                class_label = torch.tensor([1], dtype=torch.float).unsqueeze(-1)\n",
    "            else:\n",
    "                class_label = torch.tensor([0], dtype=torch.float).unsqueeze(-1)\n",
    "\n",
    "            one_graph = CustomGraphData(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y, class_label=class_label, min_vals=min_vals, max_vals=max_vals)\n",
    "            graphs_list.append(one_graph)\n",
    "\n",
    "    dataset = CustomGraphDataset(graphs_list)\n",
    "    print(f\"train dataset is done\")\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "130dd147-d59d-4235-be82-8bbc047426ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_vali_graph_data(city_name, purpose, total_ratio = 0.8 ,train_ratio = 0.6, vali_ratio = 0.2):\n",
    "    graphs_list = list()\n",
    "    \n",
    "    city_dictionary = open_data(f\"D:/ThesisData/processed data/{city_name}/NEW/{city_name}_data_14days.h5\")\n",
    "    #-----------------------------------------------------------------------------\n",
    "    subgraph = city_dictionary[\"biggest_subgraph\"]\n",
    "    sorted_nodes = sorted(subgraph.nodes())\n",
    "    #coord_list = city_dictionary[\"coord_list\"]\n",
    "    #new_coord_list = {new_key: coord_list[old_key] for new_key, old_key in enumerate(sorted_nodes, start=0) }\n",
    "    #-----------------------------------------------------------------------------\n",
    "    mapping = {old_label: new_label for new_label, old_label in enumerate(sorted_nodes, start=0)}\n",
    "    subgraph = nx.relabel_nodes(subgraph, mapping)    \n",
    "    #-----------------------------------------------------------------------------\n",
    "\n",
    "        \n",
    "    #-----------------------------------------------------------------------------\n",
    "    edge_pairs = []\n",
    "    edge_weights = []\n",
    "    for u, v, data in subgraph.edges(data=True):\n",
    "        edge_pairs.append([u, v])\n",
    "        edge_weights.append(data['weight'])\n",
    "    edge_pairs, edge_weights = np.transpose(np.array(edge_pairs)), np.array(edge_weights)        \n",
    "\n",
    "    #-----------------------------------------------------------------------------\n",
    "    total_scale, train_scale, vali_scale = 0, 0, 0\n",
    "    \n",
    "    total_scale = int(total_ratio * city_dictionary[\"input_result\"].shape[0])\n",
    "  \n",
    "\n",
    "        \n",
    "    train_scale = int(train_ratio * total_scale)\n",
    "    vali_scale = int((vali_ratio+train_ratio) * total_scale)\n",
    "    \n",
    "                \n",
    "    if purpose == \"vali\":\n",
    "        input_ = city_dictionary[\"input_result\"][train_scale: vali_scale]\n",
    "        target_ = city_dictionary[\"target_result\"][train_scale: vali_scale]  \n",
    "        print(f\"{purpose} length: {vali_scale-train_scale}\")\n",
    "            \n",
    "    if purpose == \"test\":\n",
    "        input_ = city_dictionary[\"input_result\"][vali_scale: total_scale]\n",
    "        target_ = city_dictionary[\"target_result\"][vali_scale: total_scale] \n",
    "        print(f\"{purpose} length: {total_scale - vali_scale}\")\n",
    "\n",
    "        \n",
    "    for j in range(input_.shape[0]):\n",
    "            # x  SHAPE: 28, Node_num, 1\n",
    "            #-----------------------------------------------------------\n",
    "            #first_feature = input_[..., 0]\n",
    "            #is_sorted = np.all(np.diff(first_feature, axis=-1) >= 0)\n",
    "            #print(\"Is sorted in ascending order?\", is_sorted)\n",
    "            #-----------------------------------------------------------\n",
    "        x = torch.tensor(input_[j], dtype= torch.float)[:,:,1:]\n",
    "            # x  SHAPE: Node_num, 28\n",
    "        x = x.permute(1, 0, 2).squeeze(-1)\n",
    "        if j == 1:\n",
    "            print(f\"City {city_name} {purpose} input Shape: {x.shape}\")\n",
    "        #---------------------------------\n",
    "        # y SHAPE: 14, Node_num, 1\n",
    "        y = torch.tensor(target_[j], dtype= torch.float)[:,:,1:]\n",
    "        y = y.permute(1, 0, 2).squeeze(-1)\n",
    "        #--------------------------------\n",
    "        if j == 1:\n",
    "            print(f\"City {city_name} {purpose} target Shape: {y.shape}\")\n",
    "           \n",
    "        min_vals = torch.tensor(city_dictionary[\"min_vals\"], dtype=torch.float).unsqueeze(-1).unsqueeze(-1)\n",
    "        max_vals = torch.tensor(city_dictionary[\"max_vals\"], dtype=torch.float).unsqueeze(-1).unsqueeze(-1)\n",
    "        #--------------------------------\n",
    "            \n",
    "        # EDGE INDEX SHAPE: 2, PAIR_NUM\n",
    "        edge_index = torch.tensor(edge_pairs, dtype= torch.long)\n",
    "        #  SHAPE: PAIR_NUM, \n",
    "        edge_attr = torch.tensor(edge_weights, dtype=torch.float)\n",
    "        #-----------------------------------\n",
    "            \n",
    "        if city_name==\"Antwerp\" or city_name==\"Bangkok\":\n",
    "            class_label = torch.tensor([1], dtype=torch.float).unsqueeze(-1)\n",
    "        else:\n",
    "            class_label = torch.tensor([0], dtype=torch.float).unsqueeze(-1)\n",
    "\n",
    "        one_graph = CustomGraphData(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y, class_label=class_label, min_vals=min_vals, max_vals=max_vals)\n",
    "        graphs_list.append(one_graph)\n",
    "        dataset = CustomGraphDataset(graphs_list)\n",
    "\n",
    "    \n",
    "    print(f\"{purpose} dataset is done\")\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55a629b8-684f-40bc-aa90-6d1b0dd969a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "domains = [\"Target\", \"Source\"]\n",
    "purposes = [\"vali\",\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7a6f67a-bb3a-4699-bf44-2d43896a6ca5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train length: 33\n",
      "City Barcelona train input Shape: torch.Size([1273, 28])\n",
      "City Barcelona train target Shape: torch.Size([1273, 14])\n",
      "train dataset is done\n",
      "vali length: 22\n",
      "City Barcelona vali input Shape: torch.Size([1273, 28])\n",
      "City Barcelona vali target Shape: torch.Size([1273, 14])\n",
      "vali dataset is done\n",
      "test length: 23\n",
      "City Barcelona test input Shape: torch.Size([1273, 28])\n",
      "City Barcelona test target Shape: torch.Size([1273, 14])\n",
      "test dataset is done\n",
      "train length: 67\n",
      "City Bangkok train input Shape: torch.Size([1137, 28])\n",
      "City Bangkok train target Shape: torch.Size([1137, 14])\n",
      "train length: 67\n",
      "City Antwerp train input Shape: torch.Size([1466, 28])\n",
      "City Antwerp train target Shape: torch.Size([1466, 14])\n",
      "train dataset is done\n",
      "vali length: 22\n",
      "City Bangkok vali input Shape: torch.Size([1137, 28])\n",
      "City Bangkok vali target Shape: torch.Size([1137, 14])\n",
      "vali dataset is done\n",
      "test length: 23\n",
      "City Bangkok test input Shape: torch.Size([1137, 28])\n",
      "City Bangkok test target Shape: torch.Size([1137, 14])\n",
      "test dataset is done\n",
      "vali length: 22\n",
      "City Antwerp vali input Shape: torch.Size([1466, 28])\n",
      "City Antwerp vali target Shape: torch.Size([1466, 14])\n",
      "vali dataset is done\n",
      "test length: 23\n",
      "City Antwerp test input Shape: torch.Size([1466, 28])\n",
      "City Antwerp test target Shape: torch.Size([1466, 14])\n",
      "test dataset is done\n"
     ]
    }
   ],
   "source": [
    "for domain in domains:\n",
    "    if domain == \"Source\":\n",
    "        city_names = [\"Bangkok\", \"Antwerp\"]\n",
    "    if domain == \"Target\":\n",
    "        city_names = [\"Barcelona\"]\n",
    "    dataset = create_train_graph_data(city_names)\n",
    "    torch.save(dataset, f\"D:/ThesisData/processed data/{domain}Domain/NEW/train_GCN_data_14days.h5\")\n",
    "    for city_name in city_names:\n",
    "        purposes = [\"vali\",\"test\"]\n",
    "        for purpose in purposes:\n",
    "            dataset = create_test_vali_graph_data(city_name, purpose)\n",
    "            torch.save(dataset, f\"D:/ThesisData/processed data/{domain}Domain/NEW/{city_name}_{purpose}_GCN_data_14days.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1ab6ab-4922-460e-83bc-4dbab401b258",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
