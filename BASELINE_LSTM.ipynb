{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dcc0bb0-a8f4-4d14-b7ed-d4e21490665e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.nn import init\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5e5351a-bd4c-487f-a5c4-8cd3eb1a3d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_data(file_path):\n",
    "    file = open(file_path,\"rb\")\n",
    "    raw_data = pickle.load(file)  \n",
    "    return raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "504a73f1-8096-4a6c-beb1-651466326da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(data, file_path):\n",
    "    with open(file_path , 'wb') as f:\n",
    "        pickle.dump(data,f)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f26ea2d3-207a-426e-bd4d-10769082de17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, inputs, targets, dist, dist_arg, masks, min_vals, max_vals, mask_dist_max, class_labels):\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "        self.dist = dist\n",
    "        self.dist_arg = dist_arg\n",
    "        self.masks = masks\n",
    "        self.min_vals = min_vals\n",
    "        self.max_vals = max_vals\n",
    "        self.mask_dist_max = mask_dist_max\n",
    "        self.class_labels = class_labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 获取输入和对应的目标数据\n",
    "        x = self.inputs[idx]\n",
    "        y = self.targets[idx]\n",
    "        d_ = self.dist[idx]\n",
    "        d_arg = self.dist_arg[idx]\n",
    "        mask = self.masks[idx]\n",
    "        min_ = self.min_vals[idx]\n",
    "        max_ = self.max_vals[idx]\n",
    "        mask_d_ = self.mask_dist_max[idx]\n",
    "        class_ = self.class_labels[idx]\n",
    "        return x, y, d_, d_arg, mask, min_, max_, mask_d_, class_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42e0013-af90-467e-8c0c-d18636508c96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d4d210a-0055-4b7c-b9f3-da8d6c517323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义 LSTM 模型\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, output_seq_len, drop_out = True):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers = 2, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size * output_seq_len)\n",
    "        self.output_seq_len = output_seq_len\n",
    "        self.output_size = output_size\n",
    "        self.acti_func = nn.ReLU()\n",
    "        self.drop_out = drop_out\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                #m.weight.data = init.xavier_normal_(m.weight.data, nonlinearity='relu')\n",
    "                m.weight.data = init.kaiming_normal_(m.weight.data, nonlinearity=\"relu\")\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data = init.constant_(m.bias.data, 0.0) \n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x 的形状为 (batch_size, seq_len, input_size)\n",
    "        lstm_out, _ = self.lstm(x)  # lstm_out: (batch_size, seq_len, hidden_size)\n",
    "        \n",
    "        lstm_out = lstm_out[:, -1, :]  # 取最后一个时间步的输出 (batch_size, hidden_size)\n",
    "        if self.drop_out:\n",
    "            lstm_out = F.dropout(lstm_out, training=self.training, p=0.2)\n",
    "        out = self.fc(lstm_out)# 全连接层 (batch_size, output_size * output_seq_len)\n",
    "        out= self.acti_func(out)\n",
    "        out = out.view(-1, self.output_seq_len, self.output_size)  # 重塑为 (batch_size, output_seq_len, num_nodes * num_features)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "70195a72-1a5e-43cd-8beb-5bcd9e8c9df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.load(\"D:/ThesisData/processed data/SourceDomain/NEW/train_data_14days.h5\")\n",
    "vali_bangkok = torch.load(\"D:/ThesisData/processed data/SourceDomain/NEW/Bangkok_vali_data_14days.h5\")\n",
    "vali_antwerp = torch.load(\"D:/ThesisData/processed data/SourceDomain/NEW/Antwerp_vali_data_14days.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7a992adf-6c1c-458c-aee2-052dad1a74d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bangkok = torch.load(\"D:/ThesisData/processed data/SourceDomain/NEW/Bangkok_test_data_14days.h5\")\n",
    "test_antwerp = torch.load(\"D:/ThesisData/processed data/SourceDomain/NEW/Antwerp_test_data_14days.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "385209fa-eeb6-4d05-8593-965fc1f1175c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "Bangkok_vali_loader = DataLoader(vali_bangkok, batch_size=batch_size, shuffle=False)\n",
    "Antwerp_vali_loader = DataLoader(vali_antwerp, batch_size=batch_size, shuffle=False)\n",
    "Bangkok_test_loader = DataLoader(test_bangkok, batch_size=batch_size, shuffle=False)\n",
    "Antwerp_test_loader = DataLoader(test_antwerp, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7d17941a-d875-4798-a93b-f4eb61f32bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 28\n",
    "num_nodes = 1466\n",
    "num_features = 1\n",
    "input_size = num_nodes * num_features  # LSTM 输入的维度\n",
    "hidden_size = 256   # LSTM 隐藏层的维度\n",
    "output_seq_len = 14  # 预测14天\n",
    "output_size = num_nodes * num_features  # 每个时间步预测的数据量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7d5bbf43-24b8-41e5-94be-e8daa3fbc7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMModel(input_size=input_size, hidden_size=hidden_size, output_size=output_size, output_seq_len=output_seq_len)\n",
    "criterion_MSE = nn.MSELoss(reduction='none')  # 使用均方误差作为损失函数\n",
    "criterion_MAE = nn.L1Loss(reduction='none')\n",
    "optimizer = optim.NAdam(model.parameters(), lr=4e-4, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "56d9e74e-36e9-4d5d-8b7a-663ddacb7d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_num = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d2421375-9cb0-4a59-8656-bb113e02db9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, Train: MSE=18028, MAE=104\n",
      "--Anterp Vali set: MSE=5228, MAE=47\n",
      "--Anterp Test set: MSE=8563, MAE=64\n",
      "--Bangkok Vali set: MSE=6089, MAE=56\n",
      "--Bangkok Test set: MSE=9133, MAE=72\n",
      "epoch 2, Train: MSE=10891, MAE=75\n",
      "--Anterp Vali set: MSE=4918, MAE=44\n",
      "--Anterp Test set: MSE=8061, MAE=60\n",
      "--Bangkok Vali set: MSE=5264, MAE=51\n",
      "--Bangkok Test set: MSE=7938, MAE=65\n",
      "epoch 3, Train: MSE=7154, MAE=57\n",
      "--Anterp Vali set: MSE=4408, MAE=43\n",
      "--Anterp Test set: MSE=7003, MAE=57\n",
      "--Bangkok Vali set: MSE=4348, MAE=46\n",
      "--Bangkok Test set: MSE=6257, MAE=57\n",
      "epoch 4, Train: MSE=10262, MAE=76\n",
      "--Anterp Vali set: MSE=4171, MAE=42\n",
      "--Anterp Test set: MSE=6491, MAE=55\n",
      "--Bangkok Vali set: MSE=4423, MAE=46\n",
      "--Bangkok Test set: MSE=6551, MAE=59\n",
      "epoch 5, Train: MSE=9302, MAE=71\n",
      "--Anterp Vali set: MSE=3951, MAE=43\n",
      "--Anterp Test set: MSE=6015, MAE=55\n",
      "--Bangkok Vali set: MSE=3592, MAE=44\n",
      "--Bangkok Test set: MSE=4508, MAE=49\n",
      "epoch 6, Train: MSE=7606, MAE=64\n",
      "--Anterp Vali set: MSE=3865, MAE=41\n",
      "--Anterp Test set: MSE=5883, MAE=53\n",
      "--Bangkok Vali set: MSE=3634, MAE=42\n",
      "--Bangkok Test set: MSE=4995, MAE=51\n",
      "epoch 7, Train: MSE=7362, MAE=61\n",
      "--Anterp Vali set: MSE=3671, MAE=41\n",
      "--Anterp Test set: MSE=5488, MAE=52\n",
      "--Bangkok Vali set: MSE=3250, MAE=42\n",
      "--Bangkok Test set: MSE=4159, MAE=47\n",
      "epoch 8, Train: MSE=5691, MAE=51\n",
      "--Anterp Vali set: MSE=3558, MAE=41\n",
      "--Anterp Test set: MSE=5272, MAE=51\n",
      "--Bangkok Vali set: MSE=3167, MAE=41\n",
      "--Bangkok Test set: MSE=4046, MAE=46\n",
      "epoch 9, Train: MSE=6517, MAE=60\n",
      "--Anterp Vali set: MSE=3561, MAE=39\n",
      "--Anterp Test set: MSE=5353, MAE=49\n",
      "--Bangkok Vali set: MSE=3445, MAE=41\n",
      "--Bangkok Test set: MSE=4818, MAE=50\n",
      "epoch 10, Train: MSE=5203, MAE=50\n",
      "--Anterp Vali set: MSE=3426, MAE=39\n",
      "--Anterp Test set: MSE=5000, MAE=49\n",
      "--Bangkok Vali set: MSE=3019, MAE=39\n",
      "--Bangkok Test set: MSE=3877, MAE=45\n",
      "epoch 11, Train: MSE=6313, MAE=59\n",
      "--Anterp Vali set: MSE=3637, MAE=38\n",
      "--Anterp Test set: MSE=5542, MAE=49\n",
      "--Bangkok Vali set: MSE=3717, MAE=42\n",
      "--Bangkok Test set: MSE=5623, MAE=55\n",
      "epoch 12, Train: MSE=4922, MAE=50\n",
      "--Anterp Vali set: MSE=3348, MAE=38\n",
      "--Anterp Test set: MSE=4912, MAE=48\n",
      "--Bangkok Vali set: MSE=3017, MAE=39\n",
      "--Bangkok Test set: MSE=4001, MAE=46\n",
      "epoch 13, Train: MSE=4410, MAE=46\n",
      "--Anterp Vali set: MSE=3267, MAE=39\n",
      "--Anterp Test set: MSE=4714, MAE=48\n",
      "--Bangkok Vali set: MSE=2828, MAE=39\n",
      "--Bangkok Test set: MSE=3483, MAE=43\n",
      "epoch 14, Train: MSE=4377, MAE=46\n",
      "--Anterp Vali set: MSE=3275, MAE=38\n",
      "--Anterp Test set: MSE=4730, MAE=47\n",
      "--Bangkok Vali set: MSE=2895, MAE=38\n",
      "--Bangkok Test set: MSE=3741, MAE=44\n",
      "epoch 15, Train: MSE=4702, MAE=48\n",
      "--Anterp Vali set: MSE=3244, MAE=38\n",
      "--Anterp Test set: MSE=4685, MAE=47\n",
      "--Bangkok Vali set: MSE=2841, MAE=38\n",
      "--Bangkok Test set: MSE=3654, MAE=44\n",
      "epoch 16, Train: MSE=5363, MAE=53\n",
      "--Anterp Vali set: MSE=3200, MAE=38\n",
      "--Anterp Test set: MSE=4604, MAE=47\n",
      "--Bangkok Vali set: MSE=2828, MAE=38\n",
      "--Bangkok Test set: MSE=3681, MAE=44\n",
      "epoch 17, Train: MSE=6575, MAE=59\n",
      "--Anterp Vali set: MSE=3228, MAE=40\n",
      "--Anterp Test set: MSE=4622, MAE=49\n",
      "--Bangkok Vali set: MSE=2741, MAE=38\n",
      "--Bangkok Test set: MSE=3433, MAE=42\n",
      "epoch 18, Train: MSE=4934, MAE=50\n",
      "--Anterp Vali set: MSE=3242, MAE=38\n",
      "--Anterp Test set: MSE=4674, MAE=47\n",
      "--Bangkok Vali set: MSE=2746, MAE=38\n",
      "--Bangkok Test set: MSE=3537, MAE=43\n",
      "epoch 19, Train: MSE=5736, MAE=53\n",
      "--Anterp Vali set: MSE=3476, MAE=43\n",
      "--Anterp Test set: MSE=5108, MAE=53\n",
      "--Bangkok Vali set: MSE=2721, MAE=39\n",
      "--Bangkok Test set: MSE=3343, MAE=42\n",
      "epoch 20, Train: MSE=4859, MAE=50\n",
      "--Anterp Vali set: MSE=3157, MAE=38\n",
      "--Anterp Test set: MSE=4561, MAE=46\n",
      "--Bangkok Vali set: MSE=2931, MAE=39\n",
      "--Bangkok Test set: MSE=3996, MAE=46\n",
      "epoch 21, Train: MSE=5215, MAE=51\n",
      "--Anterp Vali set: MSE=3149, MAE=38\n",
      "--Anterp Test set: MSE=4502, MAE=47\n",
      "--Bangkok Vali set: MSE=2694, MAE=38\n",
      "--Bangkok Test set: MSE=3403, MAE=42\n",
      "epoch 22, Train: MSE=4708, MAE=49\n",
      "--Anterp Vali set: MSE=3145, MAE=39\n",
      "--Anterp Test set: MSE=4481, MAE=48\n",
      "--Bangkok Vali set: MSE=2633, MAE=38\n",
      "--Bangkok Test set: MSE=3237, MAE=41\n",
      "epoch 23, Train: MSE=4755, MAE=49\n",
      "--Anterp Vali set: MSE=3121, MAE=38\n",
      "--Anterp Test set: MSE=4471, MAE=47\n",
      "--Bangkok Vali set: MSE=2620, MAE=38\n",
      "--Bangkok Test set: MSE=3225, MAE=41\n",
      "epoch 24, Train: MSE=5211, MAE=51\n",
      "--Anterp Vali set: MSE=3105, MAE=38\n",
      "--Anterp Test set: MSE=4450, MAE=47\n",
      "--Bangkok Vali set: MSE=2650, MAE=37\n",
      "--Bangkok Test set: MSE=3473, MAE=43\n",
      "epoch 25, Train: MSE=4900, MAE=50\n",
      "--Anterp Vali set: MSE=3123, MAE=38\n",
      "--Anterp Test set: MSE=4475, MAE=47\n",
      "--Bangkok Vali set: MSE=2632, MAE=37\n",
      "--Bangkok Test set: MSE=3452, MAE=43\n",
      "epoch 26, Train: MSE=4996, MAE=51\n",
      "--Anterp Vali set: MSE=3110, MAE=38\n",
      "--Anterp Test set: MSE=4450, MAE=46\n",
      "--Bangkok Vali set: MSE=2629, MAE=37\n",
      "--Bangkok Test set: MSE=3471, MAE=43\n",
      "epoch 27, Train: MSE=5007, MAE=50\n",
      "--Anterp Vali set: MSE=3132, MAE=38\n",
      "--Anterp Test set: MSE=4481, MAE=46\n",
      "--Bangkok Vali set: MSE=2685, MAE=37\n",
      "--Bangkok Test set: MSE=3741, MAE=44\n",
      "epoch 28, Train: MSE=3194, MAE=39\n",
      "--Anterp Vali set: MSE=3090, MAE=38\n",
      "--Anterp Test set: MSE=4405, MAE=47\n",
      "--Bangkok Vali set: MSE=2575, MAE=37\n",
      "--Bangkok Test set: MSE=3190, MAE=41\n",
      "epoch 29, Train: MSE=4211, MAE=45\n",
      "--Anterp Vali set: MSE=3091, MAE=38\n",
      "--Anterp Test set: MSE=4404, MAE=47\n",
      "--Bangkok Vali set: MSE=2606, MAE=37\n",
      "--Bangkok Test set: MSE=3472, MAE=43\n",
      "epoch 30, Train: MSE=4004, MAE=44\n",
      "--Anterp Vali set: MSE=3073, MAE=38\n",
      "--Anterp Test set: MSE=4386, MAE=47\n",
      "--Bangkok Vali set: MSE=2621, MAE=37\n",
      "--Bangkok Test set: MSE=3551, MAE=43\n",
      "epoch 31, Train: MSE=5358, MAE=54\n",
      "--Anterp Vali set: MSE=3087, MAE=38\n",
      "--Anterp Test set: MSE=4421, MAE=47\n",
      "--Bangkok Vali set: MSE=2788, MAE=41\n",
      "--Bangkok Test set: MSE=2819, MAE=39\n",
      "epoch 32, Train: MSE=4547, MAE=47\n",
      "--Anterp Vali set: MSE=3069, MAE=38\n",
      "--Anterp Test set: MSE=4365, MAE=47\n",
      "--Bangkok Vali set: MSE=2545, MAE=37\n",
      "--Bangkok Test set: MSE=3212, MAE=41\n",
      "epoch 33, Train: MSE=3832, MAE=42\n",
      "--Anterp Vali set: MSE=3058, MAE=39\n",
      "--Anterp Test set: MSE=4375, MAE=48\n",
      "--Bangkok Vali set: MSE=2517, MAE=37\n",
      "--Bangkok Test set: MSE=3122, MAE=41\n",
      "epoch 34, Train: MSE=3899, MAE=44\n",
      "--Anterp Vali set: MSE=3021, MAE=38\n",
      "--Anterp Test set: MSE=4329, MAE=47\n",
      "--Bangkok Vali set: MSE=2567, MAE=36\n",
      "--Bangkok Test set: MSE=3493, MAE=43\n",
      "epoch 35, Train: MSE=4294, MAE=47\n",
      "--Anterp Vali set: MSE=2989, MAE=38\n",
      "--Anterp Test set: MSE=4312, MAE=47\n",
      "--Bangkok Vali set: MSE=2482, MAE=37\n",
      "--Bangkok Test set: MSE=3109, MAE=41\n",
      "epoch 36, Train: MSE=5417, MAE=53\n",
      "--Anterp Vali set: MSE=2972, MAE=36\n",
      "--Anterp Test set: MSE=4304, MAE=45\n",
      "--Bangkok Vali set: MSE=2455, MAE=36\n",
      "--Bangkok Test set: MSE=3124, MAE=41\n",
      "epoch 37, Train: MSE=3932, MAE=45\n",
      "--Anterp Vali set: MSE=2954, MAE=37\n",
      "--Anterp Test set: MSE=4310, MAE=46\n",
      "--Bangkok Vali set: MSE=2446, MAE=36\n",
      "--Bangkok Test set: MSE=3099, MAE=40\n",
      "epoch 38, Train: MSE=4123, MAE=46\n",
      "--Anterp Vali set: MSE=2879, MAE=36\n",
      "--Anterp Test set: MSE=4188, MAE=45\n",
      "--Bangkok Vali set: MSE=2422, MAE=36\n",
      "--Bangkok Test set: MSE=2968, MAE=40\n",
      "epoch 39, Train: MSE=4632, MAE=48\n",
      "--Anterp Vali set: MSE=2854, MAE=37\n",
      "--Anterp Test set: MSE=4188, MAE=46\n",
      "--Bangkok Vali set: MSE=2434, MAE=35\n",
      "--Bangkok Test set: MSE=3292, MAE=42\n",
      "epoch 40, Train: MSE=4763, MAE=51\n",
      "--Anterp Vali set: MSE=2773, MAE=36\n",
      "--Anterp Test set: MSE=4093, MAE=45\n",
      "--Bangkok Vali set: MSE=2460, MAE=35\n",
      "--Bangkok Test set: MSE=3410, MAE=42\n"
     ]
    }
   ],
   "source": [
    "for h in range(epoch_num):\n",
    "    model.train()\n",
    "    for batch_input, batch_labels, batch_dist, batch_dist_arg, batch_masks, batch_min, batch_max, batch_dist_mask, _ in train_loader:\n",
    "        \n",
    "        batch_input, batch_labels, batch_masks = batch_input.squeeze(), batch_labels.squeeze(), batch_masks.squeeze()\n",
    "        batch_min, batch_max = batch_min.squeeze(), batch_max.squeeze()\n",
    "  \n",
    "        batch_outputs = model(batch_input)\n",
    "\n",
    "        \n",
    "        loss_mse = criterion_MSE(batch_outputs, batch_labels) * batch_masks\n",
    "        loss_mae = criterion_MAE(batch_outputs, batch_labels) * batch_masks\n",
    "        loss_mse = loss_mse.sum() / batch_masks.sum()\n",
    "        loss_mae = loss_mae.sum() / batch_masks.sum()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss_mse.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        del loss_mse\n",
    "        del loss_mae\n",
    "        \n",
    "        batch_outputs = batch_outputs * (batch_max - batch_min) + batch_min\n",
    "        batch_labels = batch_labels * (batch_max - batch_min) + batch_min\n",
    "        loss_mse = criterion_MSE(batch_outputs, batch_labels) * batch_masks\n",
    "        loss_mae = criterion_MAE(batch_outputs, batch_labels) * batch_masks\n",
    "        loss_mse = loss_mse.sum() / batch_masks.sum()\n",
    "        loss_mae = loss_mae.sum() / batch_masks.sum()\n",
    "\n",
    "    \n",
    "    print(f\"epoch {h + 1}, Train: MSE={loss_mse.item():.0f}, MAE={loss_mae.item():.0f}\")\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for batch_input, batch_labels, batch_dist, batch_dist_arg, batch_masks, batch_min, batch_max, batch_dist_mask, _ in Antwerp_vali_loader:\n",
    "        batch_input, batch_labels, batch_masks = batch_input.squeeze(), batch_labels.squeeze(), batch_masks.squeeze()\n",
    "        batch_min, batch_max = batch_min.squeeze(), batch_max.squeeze()\n",
    "        \n",
    "        batch_outputs = model(batch_input)\n",
    "        Antwerp_vali_outputs = batch_outputs * (batch_max - batch_min) + batch_min\n",
    "        Antwerp_vali_labels = batch_labels * (batch_max - batch_min) + batch_min\n",
    "        loss_mse = criterion_MSE(Antwerp_vali_outputs, Antwerp_vali_labels) * batch_masks\n",
    "        loss_mae = criterion_MAE(Antwerp_vali_outputs, Antwerp_vali_labels) * batch_masks\n",
    "        loss_mse = loss_mse.sum() / batch_masks.sum()\n",
    "        loss_mae = loss_mae.sum() / batch_masks.sum()\n",
    "\n",
    "        \n",
    "    print(f\"--Anterp Vali set: MSE={loss_mse.item():.0f}, MAE={loss_mae.item():.0f}\")  \n",
    "\n",
    "\n",
    "    for batch_input, batch_labels, batch_dist, batch_dist_arg, batch_masks, batch_min, batch_max, batch_dist_mask, _ in Antwerp_test_loader:\n",
    "        batch_input, batch_labels, batch_masks = batch_input.squeeze(), batch_labels.squeeze(), batch_masks.squeeze()\n",
    "        batch_min, batch_max = batch_min.squeeze(), batch_max.squeeze()\n",
    "        \n",
    "        batch_outputs = model(batch_input)\n",
    "        Antwerp_test_outputs = batch_outputs * (batch_max - batch_min) + batch_min\n",
    "        Antwerp_test_labels = batch_labels * (batch_max - batch_min) + batch_min\n",
    "        loss_mse = criterion_MSE(Antwerp_test_outputs, Antwerp_test_labels) * batch_masks\n",
    "        loss_mae = criterion_MAE(Antwerp_test_outputs, Antwerp_test_labels) * batch_masks\n",
    "        loss_mse = loss_mse.sum() / batch_masks.sum()\n",
    "        loss_mae = loss_mae.sum() / batch_masks.sum()\n",
    "\n",
    "        \n",
    "    print(f\"--Anterp Test set: MSE={loss_mse.item():.0f}, MAE={loss_mae.item():.0f}\") \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    for batch_input, batch_labels, batch_dist, batch_dist_arg, batch_masks, batch_min, batch_max, batch_dist_mask, _ in Bangkok_vali_loader:\n",
    "        batch_input, batch_labels, batch_masks = batch_input.squeeze(), batch_labels.squeeze(), batch_masks.squeeze()\n",
    "        batch_min, batch_max = batch_min.squeeze(), batch_max.squeeze()\n",
    "\n",
    "        batch_outputs = model(batch_input)\n",
    "        Bangkok_vali_outputs = batch_outputs * (batch_max - batch_min) + batch_min\n",
    "        Bangkok_vali_labels = batch_labels * (batch_max - batch_min) + batch_min\n",
    "        loss_mse = criterion_MSE(Bangkok_vali_outputs, Bangkok_vali_labels) * batch_masks\n",
    "        loss_mae = criterion_MAE(Bangkok_vali_outputs, Bangkok_vali_labels) * batch_masks\n",
    "        loss_mse = loss_mse.sum() / batch_masks.sum()\n",
    "        loss_mae = loss_mae.sum() / batch_masks.sum()\n",
    "\n",
    "    \n",
    "    print(f\"--Bangkok Vali set: MSE={loss_mse.item():.0f}, MAE={loss_mae.item():.0f}\")     \n",
    "\n",
    "\n",
    "    for batch_input, batch_labels, batch_dist, batch_dist_arg, batch_masks, batch_min, batch_max, batch_dist_mask, _ in Bangkok_test_loader:\n",
    "        batch_input, batch_labels, batch_masks = batch_input.squeeze(), batch_labels.squeeze(), batch_masks.squeeze()\n",
    "        batch_min, batch_max = batch_min.squeeze(), batch_max.squeeze()\n",
    "\n",
    "        batch_outputs = model(batch_input)\n",
    "        Bangkok_test_outputs = batch_outputs * (batch_max - batch_min) + batch_min\n",
    "        Bangkok_test_labels = batch_labels * (batch_max - batch_min) + batch_min\n",
    "        loss_mse = criterion_MSE(Bangkok_test_outputs, Bangkok_test_labels) * batch_masks\n",
    "        loss_mae = criterion_MAE(Bangkok_test_outputs, Bangkok_test_labels) * batch_masks\n",
    "        loss_mse = loss_mse.sum() / batch_masks.sum()\n",
    "        loss_mae = loss_mae.sum() / batch_masks.sum()\n",
    "\n",
    "    \n",
    "    print(f\"--Bangkok Test set: MSE={loss_mse.item():.0f}, MAE={loss_mae.item():.0f}\")    \n",
    "\n",
    "\n",
    "    if h == epoch_num-1:\n",
    "        lstm_results = {\"Antwerp_vali\": Antwerp_vali_outputs.detach().numpy(), \"Antwerp_vali_label\": Antwerp_vali_labels.detach().numpy(), \"Bangkok_vali\": Bangkok_vali_outputs.detach().numpy(), \"Bangkok_vali_label\": Bangkok_vali_labels.detach().numpy(),\n",
    "                    \"Antwerp_test\": Antwerp_test_outputs.detach().numpy(), \"Antwerp_test_label\": Antwerp_test_labels.detach().numpy(), \"Bangkok_test\": Bangkok_test_outputs.detach().numpy(), \"Bangkok_test_label\": Bangkok_test_labels.detach().numpy(),\n",
    "                     \"Antwerp_node_num\": 1466,  \"Bangkok_node_num\": 1137}\n",
    "        \n",
    "        save_data(lstm_results, \"D:/ThesisData/processed data/SourceDomain/NEW/results/lstm_results.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27ddb36b-d33b-4fd0-94af-e7738f133e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Model Para\n",
    "torch.save({\n",
    "    'lstm_state_dict': model.state_dict(),\n",
    "    'lstm_optimizer_state_dict': optimizer.state_dict(),\n",
    "}, 'D:/ThesisData/processed data/ModelPara/source_lstm_14days.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40aad6bd-8a5f-49cc-9950-c94d8d6acb32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load('D:/ThesisData/processed data/ModelPara/source_lstm_14days.pth')\n",
    "model.load_state_dict(checkpoint['lstm_state_dict'])\n",
    "#optimizer.load_state_dict(checkpoint['lstm_optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b14438c-368a-48d5-b8e8-79587871cfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train = torch.load(\"D:/ThesisData/processed data/TargetDomain/NEW/train_data_14days.h5\")\n",
    "vali_barcelona = torch.load(\"D:/ThesisData/processed data/TargetDomain/NEW/Barcelona_vali_data_14days.h5\")\n",
    "test_barcelona = torch.load(\"D:/ThesisData/processed data/TargetDomain/NEW/Barcelona_test_data_14days.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5fb017d8-c61f-4eb7-a31d-1f90067c118d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 14\n",
    "train_loader = DataLoader(target_train, batch_size=batch_size, shuffle=True)\n",
    "Barcelona_vali_loader = DataLoader(vali_barcelona, batch_size=batch_size, shuffle=False)\n",
    "Barcelona_test_loader = DataLoader(test_barcelona, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a1a16e96-aebd-49f9-8adf-317aedc2f54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.NAdam(model.parameters(), lr=2e-4, weight_decay=1e-5)\n",
    "lstm_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=11, gamma=0.65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "258052b5-6c0a-4ca2-bb41-f5aeb93e1657",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_num = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "58261569-eb5b-4f6c-83d9-d6313977ce65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, Train: MSE=3259, MAE=46\n",
      "--Barcelona Vali set: MSE=2881, MAE=46\n",
      "--Barcelona Test set: MSE=3846, MAE=53\n",
      "epoch 2, Train: MSE=3190, MAE=45\n",
      "--Barcelona Vali set: MSE=2871, MAE=45\n",
      "--Barcelona Test set: MSE=3827, MAE=53\n",
      "epoch 3, Train: MSE=3311, MAE=46\n",
      "--Barcelona Vali set: MSE=2553, MAE=42\n",
      "--Barcelona Test set: MSE=3389, MAE=49\n",
      "epoch 4, Train: MSE=3073, MAE=44\n",
      "--Barcelona Vali set: MSE=2961, MAE=46\n",
      "--Barcelona Test set: MSE=3920, MAE=53\n",
      "epoch 5, Train: MSE=3191, MAE=45\n",
      "--Barcelona Vali set: MSE=2838, MAE=45\n",
      "--Barcelona Test set: MSE=3724, MAE=51\n",
      "epoch 6, Train: MSE=3019, MAE=43\n",
      "--Barcelona Vali set: MSE=2953, MAE=45\n",
      "--Barcelona Test set: MSE=3860, MAE=52\n",
      "epoch 7, Train: MSE=3141, MAE=44\n",
      "--Barcelona Vali set: MSE=3003, MAE=46\n",
      "--Barcelona Test set: MSE=3913, MAE=53\n",
      "epoch 8, Train: MSE=2977, MAE=43\n",
      "--Barcelona Vali set: MSE=2892, MAE=45\n",
      "--Barcelona Test set: MSE=3769, MAE=51\n",
      "epoch 9, Train: MSE=3075, MAE=43\n",
      "--Barcelona Vali set: MSE=2824, MAE=44\n",
      "--Barcelona Test set: MSE=3681, MAE=51\n",
      "epoch 10, Train: MSE=3033, MAE=43\n",
      "--Barcelona Vali set: MSE=2613, MAE=42\n",
      "--Barcelona Test set: MSE=3412, MAE=48\n",
      "epoch 11, Train: MSE=3009, MAE=43\n",
      "--Barcelona Vali set: MSE=2913, MAE=45\n",
      "--Barcelona Test set: MSE=3826, MAE=51\n",
      "epoch 12, Train: MSE=2841, MAE=41\n",
      "--Barcelona Vali set: MSE=2813, MAE=44\n",
      "--Barcelona Test set: MSE=3682, MAE=50\n",
      "epoch 13, Train: MSE=2945, MAE=42\n",
      "--Barcelona Vali set: MSE=2943, MAE=45\n",
      "--Barcelona Test set: MSE=3855, MAE=52\n",
      "epoch 14, Train: MSE=2818, MAE=41\n",
      "--Barcelona Vali set: MSE=2839, MAE=44\n",
      "--Barcelona Test set: MSE=3730, MAE=51\n",
      "epoch 15, Train: MSE=2797, MAE=41\n",
      "--Barcelona Vali set: MSE=2799, MAE=44\n",
      "--Barcelona Test set: MSE=3687, MAE=51\n",
      "epoch 16, Train: MSE=2855, MAE=41\n",
      "--Barcelona Vali set: MSE=2644, MAE=43\n",
      "--Barcelona Test set: MSE=3474, MAE=49\n",
      "epoch 17, Train: MSE=2675, MAE=40\n",
      "--Barcelona Vali set: MSE=2670, MAE=43\n",
      "--Barcelona Test set: MSE=3519, MAE=49\n",
      "epoch 18, Train: MSE=2787, MAE=41\n",
      "--Barcelona Vali set: MSE=2641, MAE=43\n",
      "--Barcelona Test set: MSE=3486, MAE=49\n",
      "epoch 19, Train: MSE=2726, MAE=41\n",
      "--Barcelona Vali set: MSE=2745, MAE=44\n",
      "--Barcelona Test set: MSE=3655, MAE=50\n",
      "epoch 20, Train: MSE=2808, MAE=41\n",
      "--Barcelona Vali set: MSE=2588, MAE=42\n",
      "--Barcelona Test set: MSE=3441, MAE=49\n",
      "epoch 21, Train: MSE=2751, MAE=40\n",
      "--Barcelona Vali set: MSE=2459, MAE=41\n",
      "--Barcelona Test set: MSE=3266, MAE=47\n",
      "epoch 22, Train: MSE=2740, MAE=40\n",
      "--Barcelona Vali set: MSE=2640, MAE=43\n",
      "--Barcelona Test set: MSE=3509, MAE=49\n",
      "epoch 23, Train: MSE=2670, MAE=40\n",
      "--Barcelona Vali set: MSE=2788, MAE=44\n",
      "--Barcelona Test set: MSE=3733, MAE=51\n",
      "epoch 24, Train: MSE=2609, MAE=39\n",
      "--Barcelona Vali set: MSE=2627, MAE=42\n",
      "--Barcelona Test set: MSE=3505, MAE=49\n",
      "epoch 25, Train: MSE=2758, MAE=40\n",
      "--Barcelona Vali set: MSE=2697, MAE=43\n",
      "--Barcelona Test set: MSE=3626, MAE=50\n",
      "epoch 26, Train: MSE=2600, MAE=39\n",
      "--Barcelona Vali set: MSE=2564, MAE=42\n",
      "--Barcelona Test set: MSE=3435, MAE=49\n",
      "epoch 27, Train: MSE=2686, MAE=40\n",
      "--Barcelona Vali set: MSE=2572, MAE=42\n",
      "--Barcelona Test set: MSE=3448, MAE=49\n",
      "epoch 28, Train: MSE=2709, MAE=40\n",
      "--Barcelona Vali set: MSE=2619, MAE=42\n",
      "--Barcelona Test set: MSE=3525, MAE=49\n",
      "epoch 29, Train: MSE=2747, MAE=40\n",
      "--Barcelona Vali set: MSE=2453, MAE=41\n",
      "--Barcelona Test set: MSE=3291, MAE=47\n",
      "epoch 30, Train: MSE=2777, MAE=41\n",
      "--Barcelona Vali set: MSE=2612, MAE=42\n",
      "--Barcelona Test set: MSE=3525, MAE=49\n",
      "epoch 31, Train: MSE=2578, MAE=39\n",
      "--Barcelona Vali set: MSE=2415, MAE=40\n",
      "--Barcelona Test set: MSE=3229, MAE=47\n",
      "epoch 32, Train: MSE=2664, MAE=40\n",
      "--Barcelona Vali set: MSE=2432, MAE=41\n",
      "--Barcelona Test set: MSE=3268, MAE=47\n",
      "epoch 33, Train: MSE=2492, MAE=39\n",
      "--Barcelona Vali set: MSE=2323, MAE=40\n",
      "--Barcelona Test set: MSE=3116, MAE=46\n",
      "epoch 34, Train: MSE=2706, MAE=40\n",
      "--Barcelona Vali set: MSE=2458, MAE=41\n",
      "--Barcelona Test set: MSE=3319, MAE=48\n",
      "epoch 35, Train: MSE=2538, MAE=39\n",
      "--Barcelona Vali set: MSE=2432, MAE=41\n",
      "--Barcelona Test set: MSE=3283, MAE=47\n",
      "epoch 36, Train: MSE=2553, MAE=39\n",
      "--Barcelona Vali set: MSE=2250, MAE=39\n",
      "--Barcelona Test set: MSE=3012, MAE=45\n",
      "epoch 37, Train: MSE=2442, MAE=38\n",
      "--Barcelona Vali set: MSE=2202, MAE=38\n",
      "--Barcelona Test set: MSE=2943, MAE=44\n",
      "epoch 38, Train: MSE=2482, MAE=38\n",
      "--Barcelona Vali set: MSE=2360, MAE=40\n",
      "--Barcelona Test set: MSE=3186, MAE=47\n",
      "epoch 39, Train: MSE=2412, MAE=38\n",
      "--Barcelona Vali set: MSE=2351, MAE=40\n",
      "--Barcelona Test set: MSE=3175, MAE=46\n",
      "epoch 40, Train: MSE=2565, MAE=39\n",
      "--Barcelona Vali set: MSE=2364, MAE=40\n",
      "--Barcelona Test set: MSE=3200, MAE=47\n"
     ]
    }
   ],
   "source": [
    "for h in range(epoch_num):\n",
    "    model.train()\n",
    "    for batch_input, batch_labels, batch_dist, batch_dist_arg, batch_masks, batch_min, batch_max, batch_dist_mask, _ in train_loader:\n",
    "        \n",
    "        batch_input, batch_labels, batch_masks = batch_input.squeeze(), batch_labels.squeeze(), batch_masks.squeeze()\n",
    "        batch_min, batch_max = batch_min.squeeze(), batch_max.squeeze()\n",
    "        \n",
    "        \n",
    "        batch_outputs = model(batch_input)\n",
    "\n",
    "        \n",
    "        loss_mse = criterion_MSE(batch_outputs, batch_labels) * batch_masks\n",
    "        loss_mae = criterion_MAE(batch_outputs, batch_labels) * batch_masks\n",
    "        loss_mse = loss_mse.sum() / batch_masks.sum()\n",
    "        loss_mae = loss_mae.sum() / batch_masks.sum()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss_mse.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        del loss_mse\n",
    "        del loss_mae\n",
    "        \n",
    "        batch_outputs = batch_outputs * (batch_max - batch_min) + batch_min\n",
    "        batch_labels = batch_labels * (batch_max - batch_min) + batch_min\n",
    "        loss_mse = criterion_MSE(batch_outputs, batch_labels) * batch_masks\n",
    "        loss_mae = criterion_MAE(batch_outputs, batch_labels) * batch_masks\n",
    "        loss_mse = loss_mse.sum() / batch_masks.sum()\n",
    "        loss_mae = loss_mae.sum() / batch_masks.sum()\n",
    "\n",
    "    \n",
    "    print(f\"epoch {h + 1}, Train: MSE={loss_mse.item():.0f}, MAE={loss_mae.item():.0f}\")\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for batch_input, batch_labels, batch_dist, batch_dist_arg, batch_masks, batch_min, batch_max, batch_dist_mask, _ in Barcelona_vali_loader:\n",
    "        batch_input, batch_labels, batch_masks = batch_input.squeeze(), batch_labels.squeeze(), batch_masks.squeeze()\n",
    "        batch_min, batch_max = batch_min.squeeze(), batch_max.squeeze()\n",
    "        \n",
    "        batch_outputs = model(batch_input)\n",
    "        Barcelona_vali_outputs = batch_outputs * (batch_max - batch_min) + batch_min\n",
    "        Barcelona_vali_labels = batch_labels * (batch_max - batch_min) + batch_min\n",
    "        loss_mse = criterion_MSE(Barcelona_vali_outputs, Barcelona_vali_labels) * batch_masks\n",
    "        loss_mae = criterion_MAE(Barcelona_vali_outputs, Barcelona_vali_labels) * batch_masks\n",
    "        loss_mse = loss_mse.sum() / batch_masks.sum()\n",
    "        loss_mae = loss_mae.sum() / batch_masks.sum()\n",
    "\n",
    "        \n",
    "    print(f\"--Barcelona Vali set: MSE={loss_mse.item():.0f}, MAE={loss_mae.item():.0f}\")  \n",
    "\n",
    "\n",
    "    for batch_input, batch_labels, batch_dist, batch_dist_arg, batch_masks, batch_min, batch_max, batch_dist_mask, _ in Barcelona_test_loader:\n",
    "        batch_input, batch_labels, batch_masks = batch_input.squeeze(), batch_labels.squeeze(), batch_masks.squeeze()\n",
    "        batch_min, batch_max = batch_min.squeeze(), batch_max.squeeze()\n",
    "        \n",
    "        batch_outputs = model(batch_input)\n",
    "        Barcelona_test_outputs = batch_outputs * (batch_max - batch_min) + batch_min\n",
    "        Barcelona_test_labels = batch_labels * (batch_max - batch_min) + batch_min\n",
    "        loss_mse = criterion_MSE(Barcelona_test_outputs, Barcelona_test_labels) * batch_masks\n",
    "        loss_mae = criterion_MAE(Barcelona_test_outputs, Barcelona_test_labels) * batch_masks\n",
    "        loss_mse = loss_mse.sum() / batch_masks.sum()\n",
    "        loss_mae = loss_mae.sum() / batch_masks.sum()\n",
    "\n",
    "        \n",
    "    print(f\"--Barcelona Test set: MSE={loss_mse.item():.0f}, MAE={loss_mae.item():.0f}\") \n",
    "\n",
    "    lstm_scheduler.step()\n",
    "    #if h == epoch_num-1: \n",
    "        #lstm_results = {\"Barcelona_vali\": Barcelona_vali_outputs.detach().numpy(), \"Barcelona_vali_label\": Barcelona_vali_labels.detach().numpy(),\n",
    "                            #\"Barcelona_test\": Barcelona_test_outputs.detach().numpy(), \"Barcelona_test_label\": Barcelona_test_labels.detach().numpy(),\n",
    "                            #\"Barcelona_node_num\": 1273}\n",
    "        \n",
    "        #save_data(lstm_results, \"D:/ThesisData/processed data/TargetDomain/NEW/results/lstm_results.h5\")\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6680658c-119a-480a-a39a-e30f77750e76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
