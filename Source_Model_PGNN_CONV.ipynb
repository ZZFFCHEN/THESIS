{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8c06ab7-54ac-4fe5-af23-dedecfc383da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_geometric as tg\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import init\n",
    "import pdb\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch_geometric.data import Data\n",
    "import torch.optim as optim\n",
    "import scipy.interpolate as interp\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.ticker as mticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f76c6a80-e9b7-4a0b-8ac3-936445ecd238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_data(file_path):\n",
    "    file = open(file_path,\"rb\")\n",
    "    raw_data = pickle.load(file)  \n",
    "    return raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "430ffe2b-cb0c-4068-8ec9-0b37c892930b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(data, file_path):\n",
    "    with open(file_path , 'wb') as f:\n",
    "        pickle.dump(data,f)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1130b1f-cb17-4b98-980b-ee2c7950a005",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, inputs, targets, dist, dist_arg, masks, min_vals, max_vals, mask_dist_max, class_labels):\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "        self.dist = dist\n",
    "        self.dist_arg = dist_arg\n",
    "        self.masks = masks\n",
    "        self.min_vals = min_vals\n",
    "        self.max_vals = max_vals\n",
    "        self.mask_dist_max = mask_dist_max\n",
    "        self.class_labels = class_labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 获取输入和对应的目标数据\n",
    "        x = self.inputs[idx]\n",
    "        y = self.targets[idx]\n",
    "        d_ = self.dist[idx]\n",
    "        d_arg = self.dist_arg[idx]\n",
    "        mask = self.masks[idx]\n",
    "        min_ = self.min_vals[idx]\n",
    "        max_ = self.max_vals[idx]\n",
    "        mask_d_ = self.mask_dist_max[idx]\n",
    "        class_ = self.class_labels[idx]\n",
    "        return x, y, d_, d_arg, mask, min_, max_, mask_d_, class_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b8ff255-b9d6-479b-9c74-563e11392ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NonLinearOperate(nn.Module):\n",
    "    def __init__(self, input_dimen, hidden_dimen, output_dimen):\n",
    "        super(NonLinearOperate, self).__init__()  #类NonLinearLayer继承父类nn.Module的初始化方法\n",
    "        self.layer_1 = nn.Linear(input_dimen, hidden_dimen)\n",
    "        self.layer_2 = nn.Linear(hidden_dimen, output_dimen)\n",
    "        self.acti_func = nn.ReLU()\n",
    "        for m in self.modules():#遍历所有子模块\n",
    "        #Check if each sub-module is an example of the class nn.Linear\n",
    "            if isinstance(m, nn.Linear):\n",
    "                m.weight.data = init.kaiming_normal_(m.weight.data, nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data = init.constant_(m.bias.data, 0.0)\n",
    "            \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer_1(x)\n",
    "        x = self.acti_func(x)\n",
    "        x = self.layer_2(x)\n",
    "        x = self.acti_func(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3c68338-1d99-4d06-9d17-bca647883a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PGNN_Layer(nn.Module):\n",
    "    def __init__(self, hidden_dimen, output_dimen, anchor_num, drop_out = True):\n",
    "        super(PGNN_Layer, self).__init__()\n",
    "        self.drop_out = drop_out\n",
    "        self.output_dimen = output_dimen\n",
    "        self.acti_func = nn.LeakyReLU()\n",
    "        self.linear_hidden = nn.Linear(2 * anchor_num, hidden_dimen)\n",
    "        self.out_layer = nn.Linear(hidden_dimen, output_dimen)\n",
    "        \n",
    "        self.linear_structure = nn.Linear(hidden_dimen, 1)\n",
    "\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                m.weight.data = init.kaiming_uniform_(m.weight.data, nonlinearity='leaky_relu')\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data = init.constant_(m.bias.data, 0.0)                \n",
    "                    \n",
    "    def forward(self, node_features, dists_max, dists_argmax, mask_dist_max):\n",
    "        # node feature SHAPE: Batch-size, 28, Max_node_num\n",
    "        # Dist_max SHAPE: Batch-size, 28, Max_node_num, 36\n",
    "        # mask_dist_max SHAPE: Batch-size, 28, Max_node_num, 36\n",
    "        batch_size, num_days, max_node_num = node_features.size()\n",
    "        #dists_max = self.distance_calculate(dists_max.unsqueeze(-1)).squeeze()\n",
    "\n",
    "        indices_expanded = dists_argmax.flatten(start_dim=2)\n",
    "        batch_indices = torch.arange(batch_size).view(-1, 1, 1).expand(-1, num_days, indices_expanded.shape[-1])\n",
    "        day_indices = torch.arange(num_days).view(1, -1, 1).expand(batch_size, -1, indices_expanded.shape[-1]) \n",
    "        \n",
    "        subset_features = node_features[batch_indices, day_indices, indices_expanded]\n",
    "        \n",
    "    \n",
    "        #subset_features SHAPE: Batch-size, 28, Max_node_num*36\n",
    "        #subset_features = torch.gather(node_features, dim=2, index=indices_expanded)\n",
    "\n",
    "\n",
    "        #---------------------------------------------------------------\n",
    "        subset_features = subset_features.reshape(subset_features.shape[0], subset_features.shape[1], dists_argmax.shape[2], dists_argmax.shape[3])\n",
    "        #message SHAPE: Batch-size, 28, Max_node_num, 36\n",
    "        messages = subset_features * dists_max * mask_dist_max\n",
    "        feature_self = node_features.unsqueeze(-1).repeat(1, 1, 1, dists_max.shape[-1])\n",
    "        \n",
    "        #messages SHAPE: Batch-size, 28, Max_node_num * (36*2)\n",
    "        messages = torch.concat((messages, feature_self), dim = -1)\n",
    "        #---------------------------------------------------------------\n",
    "        #INPUT DIMEN:Batch-size, 28, Max_node_num, 72\n",
    "        messages = self.linear_hidden(messages)\n",
    "        if self.drop_out:\n",
    "            messages = F.dropout(messages, training=self.training, p=0.2)\n",
    "        #SHAPE: Batch-size, 28, Max_node_num, hidden_dimen\n",
    "        messages = self.acti_func(messages) \n",
    "        \n",
    "        #SHAPE: Batch-size, 28, Max_node_num, Output_dimen\n",
    "        output = self.out_layer(messages)\n",
    "        if self.drop_out:\n",
    "            output = F.dropout(output, training=self.training, p =0.2)\n",
    "        output = self.acti_func(output) \n",
    "        \n",
    "        output_structure = self.linear_structure(messages)\n",
    "        if self.drop_out:\n",
    "            output_structure = F.dropout(output_structure, training=self.training, p=0.2)\n",
    "        output_structure = self.acti_func(output_structure).unsqueeze(-1)\n",
    "        \n",
    "        \n",
    "        return output, output_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77934817-ebeb-4a43-ab83-20a40aa219ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PGNN(nn.Module):\n",
    "    def __init__(self, hidden_dimen, output_dimen, anchor_num, layer_num = 1, drop_out = True):\n",
    "        super(PGNN, self).__init__()\n",
    "        self.drop_out = drop_out\n",
    "        self.layer_num = layer_num\n",
    "        self.anchor_num = anchor_num\n",
    "        if self.layer_num == 1:\n",
    "            self.pgnn_operate_1 = PGNN_Layer(hidden_dimen, output_dimen, anchor_num, drop_out)\n",
    "        \n",
    "            \n",
    "        if self.layer_num > 1:\n",
    "            self.pgnn_operate_1 = nn.ModuleList([PGNN_Layer(hidden_dimen, output_dimen, anchor_num, drop_out) for i in range(0, layer_num)])\n",
    "           \n",
    "                \n",
    "        \n",
    "    def forward(self, x, dist_max, dist_argmax, mask_dist_max):\n",
    "\n",
    "        if self.layer_num == 1:\n",
    "            x_position, x = self.pgnn_operate_1(x, dist_max, dist_argmax, mask_dist_max)\n",
    "    \n",
    "            return x_position\n",
    "\n",
    "        \n",
    "        if self.layer_num > 1:\n",
    "            for i in range(self.layer_num):\n",
    "                _, x = self.pgnn_operate_1[i](x, dist_max, dist_argmax, mask_dist_max)\n",
    "            x_position = _   \n",
    "\n",
    "            return x_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c58c149-9ebc-4752-bce9-f7d4e17499a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PGNN处理后数据形状 : Batch_num, 28, Max_node_num, output_dimen ------> (Batch_num * Max_node_num), output_dimen, 28\n",
    "class CNN_1D(nn.Module):\n",
    "    def __init__(self, output_dimen, hidden_channels_1, hidden_channels_2):\n",
    "        super(CNN_1D, self).__init__()\n",
    "        self.conv_layer = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = output_dimen, out_channels = hidden_channels_1, kernel_size=7,  stride=1, padding=0),\n",
    "            nn.LeakyReLU(), #len 22 days\n",
    "            nn.Conv1d(in_channels = hidden_channels_1, out_channels = hidden_channels_2, kernel_size=7,  stride=1, padding=0),\n",
    "            nn.LeakyReLU(), #len 16 days\n",
    "            nn.Conv1d(in_channels = hidden_channels_2, out_channels = hidden_channels_2, kernel_size = 6, stride = 2, padding=1),\n",
    "            nn.LeakyReLU())  #len: 7 days\n",
    "\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d) or isinstance(m, nn.ConvTranspose1d):\n",
    "                # 对卷积层使用 Kaiming 正态初始化\n",
    "                nn.init.kaiming_uniform_(m.weight.data, nonlinearity='leaky_relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "        \n",
    "       \n",
    "        \n",
    "#PGNN处理后数据形状 : Batch_num, 28, Max_node_num, output_dimen ------> (Batch_num * Max_node_num), output_dimen, 28\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, max_node_num, out_dim = x.size()\n",
    "        x= x.permute(0, 2, 3, 1)\n",
    "        x = x.flatten(start_dim=0, end_dim=1)\n",
    "        #output shape: (Batch_num * Max_node_num), hidden_channels_2, 7\n",
    "        out = self.conv_layer(x) \n",
    "        #----------------------------------------------------\n",
    "        #output shape: (Batch_num * Max_node_num), 7, hidden_channels_2\n",
    "        out = out.permute(0, 2, 1)\n",
    "        #------------------------------------------------------\n",
    "\n",
    "        #out = out.view(batch_size, max_node_num, out.shape[1], out.shape[2])\n",
    "        #out = out.permute(0, 3, 1, 2)\n",
    "        #out shape: Batch_num, 7, (Max_node_num,  hidden_channels_2)\n",
    "        #out = out.flatten(start_dim = 2, end_dim = 3)\n",
    "       \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c15ac9f6-a9c0-453b-9004-e775852d0c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, output_seq_len, num_nodes, drop_out = True):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers = 1, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size * output_seq_len)\n",
    "        self.num_nodes = num_nodes\n",
    "        self.output_seq_len = output_seq_len\n",
    "        self.output_size = output_size\n",
    "        self.acti_func = nn.ReLU()\n",
    "        self.drop_out = drop_out\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                m.weight.data = init.kaiming_uniform_(m.weight.data, nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data = init.constant_(m.bias.data, 0.0) \n",
    "          \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: (Batch_num * Max_node_num), 7, hidden_size\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        if self.drop_out:\n",
    "            lstm_out = F.dropout(lstm_out, training=self.training, p=0.2)\n",
    "        lstm_out = self.acti_func(lstm_out)\n",
    "        # lstm_out shape: (Batch_num * Max_node_num), hidden_size \n",
    "        lstm_out = lstm_out[:, -1, :]\n",
    "        out = self.fc(lstm_out)  \n",
    "        out= self.acti_func(out)\n",
    "        #out shape: Batch_num, Max_node_num, output_seq_len\n",
    "        out = out.view(-1, self.num_nodes, self.output_seq_len).permute(0, 2, 1)\n",
    "         \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "498ef233-224f-44a3-b086-6e19643ede0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, output_seq_len, num_nodes, drop_out = True):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers=1, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size * output_seq_len)\n",
    "        self.num_nodes = num_nodes\n",
    "        self.output_seq_len = output_seq_len\n",
    "        self.output_size = output_size\n",
    "        self.acti_func = nn.ReLU()\n",
    "        self.drop_out = drop_out\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                m.weight.data = init.kaiming_uniform_(m.weight.data, nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data = init.constant_(m.bias.data, 0.0)  \n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: (Batch_num * Max_node_num), 7, hidden_size\n",
    "        lstm_out, _ = self.rnn(x)\n",
    "        if self.drop_out:\n",
    "            lstm_out = F.dropout(lstm_out, training=self.training, p=0.2)\n",
    "        lstm_out = self.acti_func(lstm_out)\n",
    "        # lstm_out shape: (Batch_num * Max_node_num), hidden_size \n",
    "        lstm_out = lstm_out[:, -1, :]\n",
    "        out = self.fc(lstm_out)  \n",
    "        out= self.acti_func(out)\n",
    "        #out shape: Batch_num, Max_node_num, output_seq_len\n",
    "        out = out.view(-1, self.num_nodes, self.output_seq_len).permute(0, 2, 1)\n",
    "         \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d29bd06-1705-4a15-914e-131d458ccba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------\n",
    "#PGNN\n",
    "anchor_num = 50\n",
    "num_nodes = 1466    \n",
    "hidden_dimen = 128  \n",
    "output_dimen = 64\n",
    "#-------------------------------------------------\n",
    "#CNN\n",
    "hidden_channels_1, hidden_channels_2 = 128, 64\n",
    "#-------------------------------------------------\n",
    "input_size = hidden_channels_2  # LSTM 输入的维度\n",
    "hidden_size = 128   # LSTM 隐藏层的维度\n",
    "output_seq_len = 14  # 预测14天\n",
    "output_size = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22492427-f984-4608-8396-e6d8aa7a7abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = LSTMModel(input_size, hidden_size, output_size, output_seq_len, num_nodes)\n",
    "#lstm = RNNModel(input_size, hidden_size, output_size, output_seq_len, num_nodes)\n",
    "lstm_optimizer = optim.NAdam(lstm.parameters(), lr= 4e-4, weight_decay=1e-5) #Nadam 4e-4\n",
    "lstm_scheduler = optim.lr_scheduler.StepLR(lstm_optimizer, step_size=11, gamma=0.6)\n",
    "#------------------------------------------------------------------------------------------\n",
    "pgnn = PGNN(hidden_dimen, output_dimen, anchor_num)\n",
    "cnn_pgnn_optimizer = optim.NAdam(list(pgnn.parameters()), lr= 6e-4, weight_decay=1e-5) \n",
    "cnn_pgnn_scheduler = optim.lr_scheduler.StepLR(cnn_pgnn_optimizer, step_size=11, gamma=0.55)\n",
    "cnn = CNN_1D(output_dimen, hidden_channels_1, hidden_channels_2)\n",
    "cnn_optimizer = optim.NAdam(list(cnn.parameters()), lr= 6e-4, weight_decay=1e-5) #Nadam 6e-4\n",
    "cnn_scheduler = optim.lr_scheduler.StepLR(cnn_optimizer, step_size=11, gamma=0.55)\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "criterion_MSE = nn.MSELoss(reduction='none')  # 使用均方误差作为损失函数\n",
    "criterion_MAE = nn.L1Loss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "52d0b55e-710b-4014-9fa6-bde735206786",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('D:/ThesisData/processed data/ModelPara/source_pgnn_cnn_lstm.pth')\n",
    "pgnn.load_state_dict(checkpoint['pgnn_state_dict'])\n",
    "cnn.load_state_dict(checkpoint['cnn_state_dict'])\n",
    "lstm.load_state_dict(checkpoint['lstm_state_dict'])\n",
    "cnn_pgnn_optimizer.load_state_dict(checkpoint['cnn_pgnn_optimizer_state_dict'])\n",
    "cnn_optimizer.load_state_dict(checkpoint['cnn_optimizer_state_dict'])\n",
    "lstm_optimizer.load_state_dict(checkpoint['lstm_optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1267c49-4bff-47a1-b478-81ef2a56f1fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9a10585-2080-4aef-970c-9a97edc6bd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.load(\"D:/ThesisData/processed data/SourceDomain/NEW/train_data_14days.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0414f5bf-5c35-4776-80c4-26f1fbffea1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vali_bangkok = torch.load(\"D:/ThesisData/processed data/SourceDomain/NEW/Bangkok_vali_data_14days.h5\")\n",
    "vali_antwerp = torch.load(\"D:/ThesisData/processed data/SourceDomain/NEW/Antwerp_vali_data_14days.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "261cd750-a61b-4071-a8a5-9d9e3e1c629c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bangkok = torch.load(\"D:/ThesisData/processed data/SourceDomain/NEW/Bangkok_test_data_14days.h5\")\n",
    "test_antwerp = torch.load(\"D:/ThesisData/processed data/SourceDomain/NEW/Antwerp_test_data_14days.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16412f14-96e9-4b2d-a96a-54c6f4552c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "Bangkok_vali_loader = DataLoader(vali_bangkok, batch_size=batch_size, shuffle=False)\n",
    "Antwerp_vali_loader = DataLoader(vali_antwerp, batch_size=batch_size, shuffle=False)\n",
    "Bangkok_test_loader = DataLoader(test_bangkok, batch_size=batch_size, shuffle=False)\n",
    "Antwerp_test_loader = DataLoader(test_antwerp, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ead045be-531c-4784-b8c9-e6827a75aa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_num = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10ff39d6-526f-404e-89e3-c61206549cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, Train Set Inversed Values: MSE=9031.9, MAE=71.0\n",
      "----Validation Antwerp: MSE=3652.6, MAE=38.8\n",
      "----Test Set Antwerp: MSE=5550.2, MAE=50.0\n",
      "----Vali Set Bangkok: MSE=3186.4, MAE=38.9\n",
      "----Test Set Bangkok: MSE=5128.8, MAE=52.6\n",
      "--------------------------------------------\n",
      "epoch 2, Train Set Inversed Values: MSE=6178.9, MAE=56.5\n",
      "----Validation Antwerp: MSE=3396.2, MAE=37.4\n",
      "----Test Set Antwerp: MSE=4995.0, MAE=47.6\n",
      "----Vali Set Bangkok: MSE=2611.0, MAE=35.9\n",
      "----Test Set Bangkok: MSE=4201.5, MAE=48.1\n",
      "--------------------------------------------\n",
      "epoch 3, Train Set Inversed Values: MSE=5147.3, MAE=49.7\n",
      "----Validation Antwerp: MSE=3708.1, MAE=38.2\n",
      "----Test Set Antwerp: MSE=5606.0, MAE=49.6\n",
      "----Vali Set Bangkok: MSE=3094.4, MAE=38.5\n",
      "----Test Set Bangkok: MSE=5198.9, MAE=54.0\n",
      "--------------------------------------------\n",
      "epoch 4, Train Set Inversed Values: MSE=5994.8, MAE=55.6\n",
      "----Validation Antwerp: MSE=3366.5, MAE=36.9\n",
      "----Test Set Antwerp: MSE=4957.5, MAE=47.0\n",
      "----Vali Set Bangkok: MSE=2588.0, MAE=35.5\n",
      "----Test Set Bangkok: MSE=4147.9, MAE=47.8\n",
      "--------------------------------------------\n",
      "epoch 5, Train Set Inversed Values: MSE=7787.7, MAE=62.5\n",
      "----Validation Antwerp: MSE=2988.8, MAE=35.9\n",
      "----Test Set Antwerp: MSE=4281.5, MAE=44.7\n",
      "----Vali Set Bangkok: MSE=2178.7, MAE=33.6\n",
      "----Test Set Bangkok: MSE=2931.4, MAE=39.8\n",
      "--------------------------------------------\n",
      "epoch 6, Train Set Inversed Values: MSE=5337.8, MAE=50.5\n",
      "----Validation Antwerp: MSE=3528.6, MAE=37.4\n",
      "----Test Set Antwerp: MSE=5299.6, MAE=48.1\n",
      "----Vali Set Bangkok: MSE=2918.3, MAE=37.3\n",
      "----Test Set Bangkok: MSE=4813.6, MAE=51.7\n",
      "--------------------------------------------\n",
      "epoch 7, Train Set Inversed Values: MSE=4939.8, MAE=49.7\n",
      "----Validation Antwerp: MSE=3145.8, MAE=35.7\n",
      "----Test Set Antwerp: MSE=4642.6, MAE=45.5\n",
      "----Vali Set Bangkok: MSE=2345.9, MAE=33.9\n",
      "----Test Set Bangkok: MSE=3699.6, MAE=45.0\n",
      "--------------------------------------------\n",
      "epoch 8, Train Set Inversed Values: MSE=5605.3, MAE=53.3\n",
      "----Validation Antwerp: MSE=2820.6, MAE=34.8\n",
      "----Test Set Antwerp: MSE=4009.3, MAE=43.0\n",
      "----Vali Set Bangkok: MSE=2080.0, MAE=32.9\n",
      "----Test Set Bangkok: MSE=2623.8, MAE=37.5\n",
      "--------------------------------------------\n",
      "epoch 9, Train Set Inversed Values: MSE=4969.3, MAE=52.4\n",
      "----Validation Antwerp: MSE=3602.8, MAE=37.4\n",
      "----Test Set Antwerp: MSE=5506.0, MAE=48.6\n",
      "----Vali Set Bangkok: MSE=3192.5, MAE=38.7\n",
      "----Test Set Bangkok: MSE=5300.9, MAE=54.2\n",
      "--------------------------------------------\n",
      "epoch 10, Train Set Inversed Values: MSE=5474.9, MAE=52.5\n",
      "----Validation Antwerp: MSE=3111.1, MAE=35.2\n",
      "----Test Set Antwerp: MSE=4565.4, MAE=44.5\n",
      "----Vali Set Bangkok: MSE=2397.0, MAE=34.1\n",
      "----Test Set Bangkok: MSE=3761.1, MAE=45.1\n",
      "--------------------------------------------\n",
      "epoch 11, Train Set Inversed Values: MSE=4901.1, MAE=51.6\n",
      "----Validation Antwerp: MSE=2752.8, MAE=34.1\n",
      "----Test Set Antwerp: MSE=3973.5, MAE=42.4\n",
      "----Vali Set Bangkok: MSE=2000.5, MAE=32.0\n",
      "----Test Set Bangkok: MSE=2791.3, MAE=38.6\n",
      "--------------------------------------------\n",
      "epoch 12, Train Set Inversed Values: MSE=4859.0, MAE=50.6\n",
      "----Validation Antwerp: MSE=2722.7, MAE=33.7\n",
      "----Test Set Antwerp: MSE=3909.5, MAE=41.8\n",
      "----Vali Set Bangkok: MSE=1972.5, MAE=31.7\n",
      "----Test Set Bangkok: MSE=2697.5, MAE=37.8\n",
      "--------------------------------------------\n",
      "epoch 13, Train Set Inversed Values: MSE=5527.6, MAE=56.5\n",
      "----Validation Antwerp: MSE=3097.7, MAE=34.9\n",
      "----Test Set Antwerp: MSE=4649.2, MAE=44.7\n",
      "----Vali Set Bangkok: MSE=2421.1, MAE=34.0\n",
      "----Test Set Bangkok: MSE=3940.2, MAE=46.1\n",
      "--------------------------------------------\n",
      "epoch 14, Train Set Inversed Values: MSE=4695.4, MAE=48.5\n",
      "----Validation Antwerp: MSE=2861.4, MAE=34.0\n",
      "----Test Set Antwerp: MSE=4169.5, MAE=42.5\n",
      "----Vali Set Bangkok: MSE=2108.0, MAE=32.2\n",
      "----Test Set Bangkok: MSE=3170.5, MAE=41.0\n",
      "--------------------------------------------\n",
      "epoch 15, Train Set Inversed Values: MSE=4735.1, MAE=49.6\n",
      "----Validation Antwerp: MSE=3020.3, MAE=34.4\n",
      "----Test Set Antwerp: MSE=4521.5, MAE=43.9\n",
      "----Vali Set Bangkok: MSE=2318.1, MAE=33.3\n",
      "----Test Set Bangkok: MSE=3746.5, MAE=44.8\n",
      "--------------------------------------------\n",
      "epoch 16, Train Set Inversed Values: MSE=5026.2, MAE=48.9\n",
      "----Validation Antwerp: MSE=2608.3, MAE=32.9\n",
      "----Test Set Antwerp: MSE=3758.7, MAE=40.7\n",
      "----Vali Set Bangkok: MSE=1873.9, MAE=30.9\n",
      "----Test Set Bangkok: MSE=2483.8, MAE=36.0\n",
      "--------------------------------------------\n",
      "epoch 17, Train Set Inversed Values: MSE=5212.7, MAE=51.8\n",
      "----Validation Antwerp: MSE=2667.1, MAE=33.1\n",
      "----Test Set Antwerp: MSE=3868.8, MAE=41.1\n",
      "----Vali Set Bangkok: MSE=1926.7, MAE=31.1\n",
      "----Test Set Bangkok: MSE=2684.0, MAE=37.4\n",
      "--------------------------------------------\n",
      "epoch 18, Train Set Inversed Values: MSE=5098.0, MAE=51.6\n",
      "----Validation Antwerp: MSE=2600.5, MAE=32.7\n",
      "----Test Set Antwerp: MSE=3783.9, MAE=40.7\n",
      "----Vali Set Bangkok: MSE=1859.9, MAE=30.7\n",
      "----Test Set Bangkok: MSE=2510.5, MAE=36.1\n",
      "--------------------------------------------\n",
      "epoch 19, Train Set Inversed Values: MSE=3973.2, MAE=40.7\n",
      "----Validation Antwerp: MSE=2625.4, MAE=32.9\n",
      "----Test Set Antwerp: MSE=3816.5, MAE=40.8\n",
      "----Vali Set Bangkok: MSE=1896.0, MAE=30.9\n",
      "----Test Set Bangkok: MSE=2614.9, MAE=36.8\n",
      "--------------------------------------------\n",
      "epoch 20, Train Set Inversed Values: MSE=3787.0, MAE=42.9\n",
      "----Validation Antwerp: MSE=2644.9, MAE=32.7\n",
      "----Test Set Antwerp: MSE=3869.8, MAE=40.9\n",
      "----Vali Set Bangkok: MSE=1910.1, MAE=30.8\n",
      "----Test Set Bangkok: MSE=2715.1, MAE=37.5\n",
      "--------------------------------------------\n",
      "epoch 21, Train Set Inversed Values: MSE=5212.6, MAE=52.0\n",
      "----Validation Antwerp: MSE=2643.4, MAE=32.3\n",
      "----Test Set Antwerp: MSE=3871.9, MAE=40.7\n",
      "----Vali Set Bangkok: MSE=1900.5, MAE=30.6\n",
      "----Test Set Bangkok: MSE=2690.2, MAE=37.2\n",
      "--------------------------------------------\n",
      "epoch 22, Train Set Inversed Values: MSE=3677.6, MAE=43.3\n",
      "----Validation Antwerp: MSE=2932.1, MAE=33.3\n",
      "----Test Set Antwerp: MSE=4403.3, MAE=42.9\n",
      "----Vali Set Bangkok: MSE=2224.2, MAE=32.3\n",
      "----Test Set Bangkok: MSE=3552.3, MAE=43.3\n",
      "--------------------------------------------\n",
      "epoch 23, Train Set Inversed Values: MSE=4923.7, MAE=48.2\n",
      "----Validation Antwerp: MSE=2618.3, MAE=32.2\n",
      "----Test Set Antwerp: MSE=3822.4, MAE=40.4\n",
      "----Vali Set Bangkok: MSE=1880.9, MAE=30.4\n",
      "----Test Set Bangkok: MSE=2620.5, MAE=36.7\n",
      "--------------------------------------------\n",
      "epoch 24, Train Set Inversed Values: MSE=3833.2, MAE=44.6\n",
      "----Validation Antwerp: MSE=2564.4, MAE=32.0\n",
      "----Test Set Antwerp: MSE=3762.9, MAE=40.1\n",
      "----Vali Set Bangkok: MSE=1826.9, MAE=30.1\n",
      "----Test Set Bangkok: MSE=2510.0, MAE=35.8\n",
      "--------------------------------------------\n",
      "epoch 25, Train Set Inversed Values: MSE=5159.9, MAE=51.0\n",
      "----Validation Antwerp: MSE=2654.3, MAE=32.3\n",
      "----Test Set Antwerp: MSE=3908.7, MAE=40.8\n",
      "----Vali Set Bangkok: MSE=1903.9, MAE=30.4\n",
      "----Test Set Bangkok: MSE=2761.9, MAE=37.7\n",
      "--------------------------------------------\n",
      "epoch 26, Train Set Inversed Values: MSE=5416.0, MAE=53.0\n",
      "----Validation Antwerp: MSE=2678.4, MAE=32.3\n",
      "----Test Set Antwerp: MSE=3958.2, MAE=40.9\n",
      "----Vali Set Bangkok: MSE=1917.4, MAE=30.5\n",
      "----Test Set Bangkok: MSE=2842.9, MAE=38.3\n",
      "--------------------------------------------\n",
      "epoch 27, Train Set Inversed Values: MSE=3515.8, MAE=41.4\n",
      "----Validation Antwerp: MSE=2543.7, MAE=31.8\n",
      "----Test Set Antwerp: MSE=3709.8, MAE=39.8\n",
      "----Vali Set Bangkok: MSE=1812.4, MAE=30.0\n",
      "----Test Set Bangkok: MSE=2430.9, MAE=35.1\n",
      "--------------------------------------------\n",
      "epoch 28, Train Set Inversed Values: MSE=4460.4, MAE=44.4\n",
      "----Validation Antwerp: MSE=2653.2, MAE=32.1\n",
      "----Test Set Antwerp: MSE=3906.9, MAE=40.6\n",
      "----Vali Set Bangkok: MSE=1911.7, MAE=30.4\n",
      "----Test Set Bangkok: MSE=2782.4, MAE=37.7\n",
      "--------------------------------------------\n",
      "epoch 29, Train Set Inversed Values: MSE=4536.2, MAE=48.0\n",
      "----Validation Antwerp: MSE=2688.6, MAE=32.3\n",
      "----Test Set Antwerp: MSE=3977.1, MAE=40.9\n",
      "----Vali Set Bangkok: MSE=1948.6, MAE=30.6\n",
      "----Test Set Bangkok: MSE=2909.7, MAE=38.6\n",
      "--------------------------------------------\n",
      "epoch 30, Train Set Inversed Values: MSE=4748.8, MAE=50.2\n",
      "----Validation Antwerp: MSE=2930.2, MAE=33.2\n",
      "----Test Set Antwerp: MSE=4438.1, MAE=43.0\n",
      "----Vali Set Bangkok: MSE=2241.2, MAE=32.3\n",
      "----Test Set Bangkok: MSE=3662.1, MAE=43.9\n",
      "--------------------------------------------\n",
      "epoch 31, Train Set Inversed Values: MSE=3240.3, MAE=39.1\n",
      "----Validation Antwerp: MSE=2619.5, MAE=31.9\n",
      "----Test Set Antwerp: MSE=3857.1, MAE=40.3\n",
      "----Vali Set Bangkok: MSE=1883.4, MAE=30.2\n",
      "----Test Set Bangkok: MSE=2713.2, MAE=37.2\n",
      "--------------------------------------------\n",
      "epoch 32, Train Set Inversed Values: MSE=3975.9, MAE=43.2\n",
      "----Validation Antwerp: MSE=2529.1, MAE=31.5\n",
      "----Test Set Antwerp: MSE=3681.9, MAE=39.5\n",
      "----Vali Set Bangkok: MSE=1803.9, MAE=29.7\n",
      "----Test Set Bangkok: MSE=2395.1, MAE=34.8\n",
      "--------------------------------------------\n",
      "epoch 33, Train Set Inversed Values: MSE=4634.5, MAE=47.3\n",
      "----Validation Antwerp: MSE=2577.5, MAE=31.6\n",
      "----Test Set Antwerp: MSE=3772.2, MAE=39.8\n",
      "----Vali Set Bangkok: MSE=1835.1, MAE=29.8\n",
      "----Test Set Bangkok: MSE=2552.6, MAE=35.9\n",
      "--------------------------------------------\n",
      "epoch 34, Train Set Inversed Values: MSE=2982.5, MAE=37.7\n",
      "----Validation Antwerp: MSE=2576.0, MAE=31.6\n",
      "----Test Set Antwerp: MSE=3766.0, MAE=39.8\n",
      "----Vali Set Bangkok: MSE=1832.4, MAE=29.8\n",
      "----Test Set Bangkok: MSE=2544.2, MAE=35.8\n",
      "--------------------------------------------\n",
      "epoch 35, Train Set Inversed Values: MSE=4106.0, MAE=44.6\n",
      "----Validation Antwerp: MSE=2599.5, MAE=31.6\n",
      "----Test Set Antwerp: MSE=3802.1, MAE=39.9\n",
      "----Vali Set Bangkok: MSE=1853.8, MAE=29.8\n",
      "----Test Set Bangkok: MSE=2605.6, MAE=36.3\n",
      "--------------------------------------------\n",
      "epoch 36, Train Set Inversed Values: MSE=4343.8, MAE=47.6\n",
      "----Validation Antwerp: MSE=2654.9, MAE=31.8\n",
      "----Test Set Antwerp: MSE=3903.4, MAE=40.3\n",
      "----Vali Set Bangkok: MSE=1903.4, MAE=30.1\n",
      "----Test Set Bangkok: MSE=2784.1, MAE=37.6\n",
      "--------------------------------------------\n",
      "epoch 37, Train Set Inversed Values: MSE=3816.9, MAE=41.2\n",
      "----Validation Antwerp: MSE=2518.9, MAE=31.3\n",
      "----Test Set Antwerp: MSE=3671.8, MAE=39.3\n",
      "----Vali Set Bangkok: MSE=1777.7, MAE=29.4\n",
      "----Test Set Bangkok: MSE=2368.9, MAE=34.5\n",
      "--------------------------------------------\n",
      "epoch 38, Train Set Inversed Values: MSE=3267.5, MAE=39.2\n",
      "----Validation Antwerp: MSE=2576.2, MAE=31.5\n",
      "----Test Set Antwerp: MSE=3777.4, MAE=39.8\n",
      "----Vali Set Bangkok: MSE=1822.4, MAE=29.6\n",
      "----Test Set Bangkok: MSE=2563.5, MAE=35.9\n",
      "--------------------------------------------\n",
      "epoch 39, Train Set Inversed Values: MSE=4269.9, MAE=44.6\n",
      "----Validation Antwerp: MSE=2504.0, MAE=31.2\n",
      "----Test Set Antwerp: MSE=3652.3, MAE=39.2\n",
      "----Vali Set Bangkok: MSE=1767.7, MAE=29.3\n",
      "----Test Set Bangkok: MSE=2338.1, MAE=34.2\n",
      "--------------------------------------------\n",
      "epoch 40, Train Set Inversed Values: MSE=4091.6, MAE=44.5\n",
      "----Validation Antwerp: MSE=2674.7, MAE=31.9\n",
      "----Test Set Antwerp: MSE=3960.7, MAE=40.6\n",
      "----Vali Set Bangkok: MSE=1924.2, MAE=30.2\n",
      "----Test Set Bangkok: MSE=2902.8, MAE=38.4\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for h in range(epoch_num):\n",
    "    lstm.train()\n",
    "    pgnn.train()\n",
    "    cnn.train()\n",
    "    \n",
    "    \n",
    "    for batch_input, batch_labels, batch_dist, batch_dist_arg, batch_masks, batch_min, batch_max, batch_dist_mask, _ in train_loader:\n",
    "\n",
    "        \n",
    "        batch_input, batch_labels, batch_masks = batch_input.squeeze(), batch_labels.squeeze(), batch_masks.squeeze()\n",
    "        batch_min, batch_max = batch_min.squeeze(), batch_max.squeeze()\n",
    "  \n",
    "        \n",
    "\n",
    "        \n",
    "        pgnn_output = pgnn(batch_input, batch_dist, batch_dist_arg, batch_dist_mask)\n",
    "        cnn_output = cnn(pgnn_output)\n",
    "        \n",
    "        batch_outputs = lstm(cnn_output)\n",
    "      \n",
    "        \n",
    "        loss_mse = criterion_MSE(batch_outputs, batch_labels) * batch_masks\n",
    "        loss_mae = criterion_MAE(batch_outputs, batch_labels) * batch_masks\n",
    "        loss_mse = loss_mse.sum() / batch_masks.sum()\n",
    "        loss_mae = loss_mae.sum() / batch_masks.sum()\n",
    "        \n",
    "        lstm_optimizer.zero_grad()\n",
    "        cnn_pgnn_optimizer.zero_grad()\n",
    "        cnn_optimizer.zero_grad()\n",
    "\n",
    "       \n",
    "        loss_mse.backward()\n",
    "\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(lstm.parameters(), 1.0)\n",
    "        torch.nn.utils.clip_grad_norm_(cnn.parameters(), 1.0)\n",
    "        torch.nn.utils.clip_grad_norm_(pgnn.parameters(), 1.0)\n",
    "\n",
    "        \n",
    "        lstm_optimizer.step()\n",
    "        cnn_pgnn_optimizer.step()\n",
    "        cnn_optimizer.step()\n",
    "        \n",
    "        del loss_mse\n",
    "        del loss_mae\n",
    "        #----------------------------------------------------------------------\n",
    "        inverse_outputs = batch_outputs * (batch_max - batch_min) + batch_min\n",
    "        inverse_labels = batch_labels * (batch_max - batch_min) + batch_min\n",
    "\n",
    "        \n",
    "        loss_mse = criterion_MSE(inverse_outputs, inverse_labels) * batch_masks\n",
    "        loss_mae = criterion_MAE(inverse_outputs, inverse_labels) * batch_masks\n",
    "        \n",
    "        \n",
    "        \n",
    "        loss_mse = loss_mse.sum() / batch_masks.sum()\n",
    "        loss_mae = loss_mae.sum() / batch_masks.sum()    \n",
    "        \n",
    "        del batch_outputs\n",
    "        del batch_labels\n",
    "        del inverse_outputs\n",
    "        del inverse_labels\n",
    "        del batch_min\n",
    "        del batch_max\n",
    "\n",
    "    \n",
    "    print(f\"epoch {h + 1}, Train Set Inversed Values: MSE={loss_mse.item():.1f}, MAE={loss_mae.item():.1f}\")  \n",
    "    \n",
    "    \n",
    "#--------------------------------------------------\n",
    "    lstm.eval()\n",
    "    pgnn.eval()\n",
    "    cnn.eval()  \n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        for batch_input, batch_labels, batch_dist, batch_dist_arg, batch_masks, batch_min, batch_max, batch_dist_mask, _ in Antwerp_vali_loader:\n",
    "            batch_input, batch_labels, batch_masks = batch_input.squeeze(), batch_labels.squeeze(), batch_masks.squeeze()\n",
    "            batch_min, batch_max = batch_min.squeeze(), batch_max.squeeze()\n",
    "\n",
    "\n",
    "            pgnn_output = pgnn(batch_input, batch_dist, batch_dist_arg, batch_dist_mask)\n",
    "            cnn_output = cnn(pgnn_output)\n",
    "            batch_outputs = lstm(cnn_output)           \n",
    "\n",
    "      \n",
    "            del pgnn_output\n",
    "            del cnn_output\n",
    "\n",
    "\n",
    "            #----------------------------------------------------------------------\n",
    "            Antwerp_vali_outputs = batch_outputs * (batch_max - batch_min) + batch_min\n",
    "            Antwerp_vali_labels = batch_labels * (batch_max - batch_min) + batch_min            \n",
    "            #----------------------------------------------------------------------\n",
    "        \n",
    "\n",
    "            loss_mse = criterion_MSE(Antwerp_vali_outputs, Antwerp_vali_labels) * batch_masks\n",
    "            loss_mae = criterion_MAE(Antwerp_vali_outputs, Antwerp_vali_labels) * batch_masks\n",
    "            loss_mse = loss_mse.sum() / batch_masks.sum()\n",
    "            loss_mae = loss_mae.sum() / batch_masks.sum()   \n",
    "\n",
    "          \n",
    "        print(f\"----Validation Antwerp: MSE={loss_mse.item():.1f}, MAE={loss_mae.item():.1f}\")\n",
    "\n",
    "\n",
    "        for batch_input, batch_labels, batch_dist, batch_dist_arg, batch_masks, batch_min, batch_max, batch_dist_mask, _ in Antwerp_test_loader:\n",
    "            batch_input, batch_labels, batch_masks = batch_input.squeeze(), batch_labels.squeeze(), batch_masks.squeeze()\n",
    "            batch_min, batch_max = batch_min.squeeze(), batch_max.squeeze()\n",
    "\n",
    "\n",
    "            pgnn_output = pgnn(batch_input, batch_dist, batch_dist_arg, batch_dist_mask)\n",
    "            cnn_output = cnn(pgnn_output)\n",
    "            batch_outputs = lstm(cnn_output)           \n",
    "\n",
    "      \n",
    "            del pgnn_output\n",
    "            del cnn_output\n",
    "\n",
    "\n",
    "            #----------------------------------------------------------------------\n",
    "            Antwerp_test_outputs = batch_outputs * (batch_max - batch_min) + batch_min\n",
    "            Antwerp_test_labels = batch_labels * (batch_max - batch_min) + batch_min            \n",
    "            #----------------------------------------------------------------------\n",
    "        \n",
    "\n",
    "            loss_mse = criterion_MSE(Antwerp_test_outputs, Antwerp_test_labels) * batch_masks\n",
    "            loss_mae = criterion_MAE(Antwerp_test_outputs, Antwerp_test_labels) * batch_masks\n",
    "            loss_mse = loss_mse.sum() / batch_masks.sum()\n",
    "            loss_mae = loss_mae.sum() / batch_masks.sum()   \n",
    "\n",
    "          \n",
    "        print(f\"----Test Set Antwerp: MSE={loss_mse.item():.1f}, MAE={loss_mae.item():.1f}\")\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "#----------------------------------------------------------------------------------------------------------------------------------------------\n",
    "        for batch_input, batch_labels, batch_dist, batch_dist_arg, batch_masks, batch_min, batch_max, batch_dist_mask, _ in Bangkok_vali_loader:\n",
    "            batch_input, batch_labels, batch_masks = batch_input.squeeze(), batch_labels.squeeze(), batch_masks.squeeze()\n",
    "            batch_min, batch_max = batch_min.squeeze(), batch_max.squeeze()\n",
    "\n",
    "            \n",
    "            pgnn_output = pgnn(batch_input, batch_dist, batch_dist_arg, batch_dist_mask)\n",
    "            cnn_output = cnn(pgnn_output)\n",
    "        \n",
    "            batch_outputs = lstm(cnn_output)\n",
    "\n",
    "\n",
    "            #----------------------------------------------------------------------\n",
    "            Bangkok_vali_outputs = batch_outputs * (batch_max - batch_min) + batch_min\n",
    "            Bangkok_vali_labels = batch_labels * (batch_max - batch_min) + batch_min\n",
    "\n",
    "            loss_mse = criterion_MSE(Bangkok_vali_outputs, Bangkok_vali_labels) * batch_masks\n",
    "            loss_mae = criterion_MAE(Bangkok_vali_outputs, Bangkok_vali_labels) * batch_masks\n",
    "            loss_mse = loss_mse.sum() / batch_masks.sum()\n",
    "            loss_mae = loss_mae.sum() / batch_masks.sum()    \n",
    "\n",
    "            \n",
    "        print(f\"----Vali Set Bangkok: MSE={loss_mse.item():.1f}, MAE={loss_mae.item():.1f}\")   \n",
    "\n",
    "\n",
    "        for batch_input, batch_labels, batch_dist, batch_dist_arg, batch_masks, batch_min, batch_max, batch_dist_mask, _ in Bangkok_test_loader:\n",
    "            batch_input, batch_labels, batch_masks = batch_input.squeeze(), batch_labels.squeeze(), batch_masks.squeeze()\n",
    "            batch_min, batch_max = batch_min.squeeze(), batch_max.squeeze()\n",
    "\n",
    "            \n",
    "            pgnn_output = pgnn(batch_input, batch_dist, batch_dist_arg, batch_dist_mask)\n",
    "            cnn_output = cnn(pgnn_output)\n",
    "        \n",
    "            batch_outputs = lstm(cnn_output)\n",
    "\n",
    "\n",
    "            #----------------------------------------------------------------------\n",
    "            Bangkok_test_outputs = batch_outputs * (batch_max - batch_min) + batch_min\n",
    "            Bangkok_test_labels = batch_labels * (batch_max - batch_min) + batch_min\n",
    "\n",
    "            loss_mse = criterion_MSE(Bangkok_test_outputs, Bangkok_test_labels) * batch_masks\n",
    "            loss_mae = criterion_MAE(Bangkok_test_outputs, Bangkok_test_labels) * batch_masks\n",
    "            loss_mse = loss_mse.sum() / batch_masks.sum()\n",
    "            loss_mae = loss_mae.sum() / batch_masks.sum()    \n",
    "\n",
    "            \n",
    "        print(f\"----Test Set Bangkok: MSE={loss_mse.item():.1f}, MAE={loss_mae.item():.1f}\")   \n",
    "        print(\"--------------------------------------------\")\n",
    "\n",
    "\n",
    "    if h == epoch_num-1: #epoch_num-1:\n",
    "        pgnn_cnn_results = {\"Antwerp_vali\": Antwerp_vali_outputs.detach().numpy(), \"Antwerp_vali_label\": Antwerp_vali_labels.detach().numpy(), \"Bangkok_vali\": Bangkok_vali_outputs.detach().numpy(), \"Bangkok_vali_label\": Bangkok_vali_labels.detach().numpy(),\n",
    "                    \"Antwerp_test\": Antwerp_test_outputs.detach().numpy(), \"Antwerp_test_label\": Antwerp_test_labels.detach().numpy(), \"Bangkok_test\": Bangkok_test_outputs.detach().numpy(), \"Bangkok_test_label\": Bangkok_test_labels.detach().numpy(),\n",
    "                     \"Antwerp_node_num\": 1466,  \"Bangkok_node_num\": 1137}\n",
    "\n",
    "        save_data(pgnn_cnn_results,\"D:/ThesisData/processed data/SourceDomain/NEW/results/pgnn_cnn_rnn_results.h5\" )    \n",
    "\n",
    "    \n",
    "    lstm_scheduler.step()\n",
    "    cnn_pgnn_scheduler.step()\n",
    "    cnn_scheduler.step()\n",
    "\n",
    "    \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8e3a9268-f580-4a3c-a408-203640b535d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Model Para\n",
    "torch.save({\n",
    "    'pgnn_state_dict': pgnn.state_dict(),\n",
    "    'rnn_state_dict': lstm.state_dict(),\n",
    "    'cnn_state_dict': cnn.state_dict(),\n",
    "    'rnn_optimizer_state_dict': lstm_optimizer.state_dict(),\n",
    "    'cnn_pgnn_optimizer_state_dict': cnn_pgnn_optimizer.state_dict(),\n",
    "    'cnn_optimizer_state_dict': cnn_optimizer.state_dict(),\n",
    "}, 'D:/ThesisData/processed data/ModelPara/source_pgnn_cnn_lstm_14days.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9d6c01-ce20-442b-a2f6-c18a5d7ec1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
